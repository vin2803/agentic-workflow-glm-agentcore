{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Building an Agentic Stock Analyzer: LangGraph + Amazon SageMaker Jumpstart + Amazon Bedrock AgentCore\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we will learn how to build and deploy an intelligent stock analysis agent using Amazon Bedrock \n",
    "AgentCore Runtime with LangGraph and Amazon SageMaker.\n",
    "\n",
    "We will focus on creating a complete stock investment workflow that combines:\n",
    "• **LangGraph** for multi-step agent orchestration\n",
    "• **Amazon SageMaker** with GLM 4.5 model for natural language processing\n",
    "• **Custom stock analysis tools** for data gathering, performance analysis, and investment decisions\n",
    "• **Amazon Bedrock AgentCore Runtime** for scalable cloud deployment\n",
    "• **Amazon S3** for automated PDF report generation and storage\n",
    "\n",
    "This example demonstrates how to transform simple stock ticker requests into comprehensive investment analysis with \n",
    "automated buy/sell/hold recommendations, complete with risk assessments and professional PDF reports.\n",
    "\n",
    "For other agent frameworks and model combinations, check out:\n",
    "• [Strands Agents with Amazon Bedrock models](../01-strands-with-bedrock-model)\n",
    "• [Strands Agents with OpenAI models](../03-strands-with-openai-model)\n",
    "\n",
    "### Demo Details\n",
    "\n",
    "| Information         | Details                                                                      |\n",
    "|:--------------------|:-----------------------------------------------------------------------------|\n",
    "| Demo type           | Conversational                                                               |\n",
    "| Agent type          | Single                                                                       |\n",
    "| Agentic Framework   | LangGraph                                                                    |\n",
    "| LLM model           | Hugging Face GLM 4.5 Air 109b                                                |\n",
    "| Demo components     | Hosting agent on AgentCore Runtime. Using LangGraph, HuggingFace Model, and S3 |\n",
    "| Tutorial vertical   | Financial Services / Investment Analysis                                     |\n",
    "| Example complexity  | Intermediate                                                                 |\n",
    "| SDK used            | Amazon BedrockAgentCore Python SDK, boto3, yfinance                          |\n",
    "\n",
    "### Demo Architecture\n",
    "\n",
    "In this tutorial we will describe how to deploy an existing agent to AgentCore runtime.\n",
    "\n",
    "For demonstration purposes, we will use a LangGraph agent using Amazon SageMaker with GLM 4.5 Air model for \n",
    "intelligent stock analysis and investment recommendations.\n",
    "\n",
    "In our example we will use a sophisticated stock analysis agent with three specialized tools:  \n",
    "\n",
    "• gather_stock_data - Collects real-time market data, financial metrics, and company information  \n",
    "• analyze_stock_performance - Performs comprehensive technical and fundamental analysis with risk assessment    \n",
    "• The generate_stock_report tool creates professional PDF reports from the gathered stock data and analysis, automatically uploading them to Amazon S3 with organized date-based folders. \n",
    "\n",
    "This agent demonstrates a complete end-to-end workflow that transforms simple stock symbol requests into professional investment analysis with calculated risk levels, position sizing recommendations, and automated PDF report storage in Amazon S3.\n",
    "\n",
    "### Demo Key Features  \n",
    "  \n",
    "• Hosting Agents on Amazon Bedrock AgentCore Runtime  \n",
    "• Using Amazon Sagemaker AI models, especially GLM 4.5 Air model  \n",
    "• Using LangGraph for multi-agent orchestration  \n",
    "• Real-time stock data integration with yfinance API  \n",
    "• Automated PDF report generation with ReportLab  \n",
    "• Amazon S3 integration for document storage  \n",
    "• Comprehensive investment analysis with technical and fundamental metrics  \n",
    "• Risk-adjusted portfolio recommendations  \n",
    "\n",
    "### What You'll Build\n",
    "\n",
    "By the end of this tutorial, you'll have a production-ready stock analysis agent that can:\n",
    "\n",
    "1. Accept natural language requests like \"Analyze AMZN stock for investment\"\n",
    "2. Gather comprehensive market data including current prices, financial ratios, and historical performance\n",
    "3. Perform professional analysis using both technical indicators and fundamental metrics\n",
    "4. Create detailed PDF reports with executive summaries, risk assessments, and monitoring recommendations\n",
    "5. Store reports automatically in Amazon S3 with organized date-based folder structure\n",
    "6. Scale seamlessly using Amazon Bedrock AgentCore Runtime infrastructure\n",
    "\n",
    "This intelligent agent combines the power of real-time market data, advanced AI analysis, and professional report \n",
    "generation to provide institutional-quality investment research at scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To execute this tutorial you will need:\n",
    "* Python 3.10+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* LangGraph\n",
    "* Docker running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bedrock-agentcore (from -r requirements.txt (line 1))\n",
      "  Using cached bedrock_agentcore-1.0.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting bedrock-agentcore-starter-toolkit==0.1.1 (from -r requirements.txt (line 2))\n",
      "  Using cached bedrock_agentcore_starter_toolkit-0.1.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting uv (from -r requirements.txt (line 3))\n",
      "  Using cached uv-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting langgraph (from -r requirements.txt (line 5))\n",
      "  Using cached langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting duckduckgo-search (from -r requirements.txt (line 7))\n",
      "  Using cached duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain-community (from -r requirements.txt (line 8))\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting opentelemetry-instrumentation-langchain (from -r requirements.txt (line 9))\n",
      "  Using cached opentelemetry_instrumentation_langchain-0.48.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting starlette (from -r requirements.txt (line 10))\n",
      "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting uvicorn (from -r requirements.txt (line 11))\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting boto3 (from -r requirements.txt (line 12))\n",
      "  Using cached boto3-1.40.74-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting botocore (from -r requirements.txt (line 13))\n",
      "  Using cached botocore-1.40.74-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting yfinance (from -r requirements.txt (line 14))\n",
      "  Using cached yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 15))\n",
      "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 16))\n",
      "  Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting requests (from -r requirements.txt (line 17))\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting reportlab (from -r requirements.txt (line 18))\n",
      "  Using cached reportlab-4.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting matplotlib (from -r requirements.txt (line 19))\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn (from -r requirements.txt (line 20))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting python-dateutil (from -r requirements.txt (line 21))\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz (from -r requirements.txt (line 22))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting langchain[aws] (from -r requirements.txt (line 4))\n",
      "  Using cached langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langsmith[otel] (from -r requirements.txt (line 6))\n",
      "  Using cached langsmith-0.4.43-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx>=0.28.1 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jinja2>=3.1.6 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting prompt-toolkit>=3.0.51 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting pyyaml>=6.0.2 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting rich<15.0.0,>=14.0.0 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting toml>=0.10.2 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typer>=0.16.0 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.13.2 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting urllib3>=1.26.0 (from bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.0.0->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.0.0->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<15.0.0,>=14.0.0->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich<15.0.0,>=14.0.0->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.4 (from langchain[aws]->-r requirements.txt (line 4))\n",
      "  Using cached langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-aws (from langchain[aws]->-r requirements.txt (line 4))\n",
      "  Using cached langchain_aws-1.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph->-r requirements.txt (line 5))\n",
      "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph->-r requirements.txt (line 5))\n",
      "  Using cached langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph->-r requirements.txt (line 5))\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph->-r requirements.txt (line 5))\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.4->langchain[aws]->-r requirements.txt (line 4))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<26.0.0,>=23.2.0 (from langchain-core<2.0.0,>=1.0.4->langchain[aws]->-r requirements.txt (line 4))\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.4->langchain[aws]->-r requirements.txt (line 4))\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain[aws]->-r requirements.txt (line 4))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph->-r requirements.txt (line 5))\n",
      "  Using cached ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph->-r requirements.txt (line 5))\n",
      "  Using cached orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx>=0.28.1->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx>=0.28.1->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.28.1->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.28.1->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.28.1->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting opentelemetry-api>=1.30.0 (from langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.30.0 (from langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting click>=8.1.8 (from duckduckgo-search->-r requirements.txt (line 7))\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search->-r requirements.txt (line 7))\n",
      "  Using cached primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search->-r requirements.txt (line 7))\n",
      "  Using cached lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->-r requirements.txt (line 17))\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 8))\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting opentelemetry-instrumentation>=0.50b0 (from opentelemetry-instrumentation-langchain->-r requirements.txt (line 9))\n",
      "  Using cached opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions>=0.55b0 (from opentelemetry-instrumentation-langchain->-r requirements.txt (line 9))\n",
      "  Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.13 (from opentelemetry-instrumentation-langchain->-r requirements.txt (line 9))\n",
      "  Using cached opentelemetry_semantic_conventions_ai-0.4.13-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.30.0->langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.30.0->langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.28.1->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r requirements.txt (line 12))\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->-r requirements.txt (line 12))\n",
      "  Using cached s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting six>=1.5 (from python-dateutil->-r requirements.txt (line 21))\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached multitasking-0.0.12-py3-none-any.whl\n",
      "Collecting platformdirs>=2.0.0 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting frozendict>=2.3.4 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached peewee-3.18.3-cp312-cp312-linux_x86_64.whl\n",
      "Collecting beautifulsoup4>=4.11.1 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting curl_cffi>=0.7 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting websockets>=13.0 (from yfinance->-r requirements.txt (line 14))\n",
      "  Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 15))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pillow>=9.0.0 (from reportlab->-r requirements.txt (line 18))\n",
      "  Using cached pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 19))\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 19))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 19))\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 19))\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->-r requirements.txt (line 19))\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 14))\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting cffi>=1.12.0 (from curl_cffi>=0.7->yfinance->-r requirements.txt (line 14))\n",
      "  Using cached cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=1.12.0->curl_cffi>=0.7->yfinance->-r requirements.txt (line 14))\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=3.1.6->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->langsmith[otel]->-r requirements.txt (line 6))\n",
      "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation>=0.50b0->opentelemetry-instrumentation-langchain->-r requirements.txt (line 9))\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting wcwidth (from prompt-toolkit>=3.0.51->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.16.0->bedrock-agentcore-starter-toolkit==0.1.1->-r requirements.txt (line 2))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Using cached bedrock_agentcore_starter_toolkit-0.1.1-py3-none-any.whl (77 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached bedrock_agentcore-1.0.6-py3-none-any.whl (87 kB)\n",
      "Using cached uv-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
      "Using cached langchain-1.0.7-py3-none-any.whl (93 kB)\n",
      "Using cached langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
      "Using cached langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Using cached langsmith-0.4.43-py3-none-any.whl (410 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Using cached sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Using cached opentelemetry_instrumentation_langchain-0.48.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached opentelemetry_semantic_conventions_ai-0.4.13-py3-none-any.whl (6.1 kB)\n",
      "Using cached starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Using cached boto3-1.40.74-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.40.74-py3-none-any.whl (14.1 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Using cached yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached reportlab-4.4.4-py3-none-any.whl (2.0 MB)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Using cached frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
      "Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Using cached greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
      "Using cached wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Using cached orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Using cached ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Using cached platformdirs-4.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
      "Using cached langchain_aws-1.0.0-py3-none-any.whl (150 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Using cached wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pytz, peewee, multitasking, zstandard, zipp, xxhash, wrapt, websockets, wcwidth, uv, urllib3, tzdata, typing-extensions, toml, tenacity, soupsieve, sniffio, six, shellingham, pyyaml, python-dotenv, pyparsing, pygments, pycparser, protobuf, propcache, primp, platformdirs, pillow, packaging, ormsgpack, orjson, opentelemetry-semantic-conventions-ai, numpy, mypy-extensions, multidict, mdurl, MarkupSafe, lxml, kiwisolver, jsonpointer, jmespath, idna, httpx-sse, h11, greenlet, frozenlist, frozendict, fonttools, docstring-parser, cycler, click, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspection, typing-inspect, SQLAlchemy, requests, reportlab, python-dateutil, pydantic-core, prompt-toolkit, opentelemetry-proto, marshmallow, markdown-it-py, jsonpatch, jinja2, importlib-metadata, httpcore, googleapis-common-protos, duckduckgo-search, contourpy, cffi, beautifulsoup4, anyio, aiosignal, starlette, rich, requests-toolbelt, pydantic, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, matplotlib, httpx, dataclasses-json, curl_cffi, botocore, aiohttp, yfinance, typer, seaborn, s3transfer, pydantic-settings, opentelemetry-semantic-conventions, langsmith, langgraph-sdk, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, boto3, opentelemetry-instrumentation-langchain, opentelemetry-exporter-otlp-proto-http, langgraph-checkpoint, langchain-text-splitters, langchain-aws, bedrock-agentcore, langgraph-prebuilt, langchain-classic, bedrock-agentcore-starter-toolkit, langgraph, langchain-community, langchain\n",
      "\u001b[2K  Attempting uninstall: pytz\n",
      "\u001b[2K    Found existing installation: pytz 2025.2\n",
      "\u001b[2K    Uninstalling pytz-2025.2:\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2\n",
      "\u001b[2K  Attempting uninstall: peewee━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  0/118\u001b[0m [pytz]\n",
      "\u001b[2K    Found existing installation: peewee 3.18.30m \u001b[32m  0/118\u001b[0m [pytz]\n",
      "\u001b[2K    Uninstalling peewee-3.18.3:━━━━━━━━━━━━━\u001b[0m \u001b[32m  0/118\u001b[0m [pytz]\n",
      "\u001b[2K      Successfully uninstalled peewee-3.18.3━━━━\u001b[0m \u001b[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: multitasking━━━━━━━━━━━━\u001b[0m \u001b[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K    Found existing installation: multitasking 0.0.122m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K    Uninstalling multitasking-0.0.12:━━━━━━━\u001b[0m \u001b[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K      Successfully uninstalled multitasking-0.0.12[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: zstandard━━━━━━━━━━━\u001b[0m \u001b[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K    Found existing installation: zstandard 0.25.0\u001b[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K    Uninstalling zstandard-0.25.0:━━━━━━━━━━\u001b[0m \u001b[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K      Successfully uninstalled zstandard-0.25.0m \u001b[32m  1/118\u001b[0m [peewee]\n",
      "\u001b[2K  Attempting uninstall: zipp━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  3/118\u001b[0m [zstandard]\n",
      "\u001b[2K    Found existing installation: zipp 3.23.0━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]]\n",
      "\u001b[2K    Uninstalling zipp-3.23.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K      Successfully uninstalled zipp-3.23.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K  Attempting uninstall: xxhash━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K    Found existing installation: xxhash 3.6.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K    Uninstalling xxhash-3.6.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K      Successfully uninstalled xxhash-3.6.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K  Attempting uninstall: wrapt━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K    Found existing installation: wrapt 1.17.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K    Uninstalling wrapt-1.17.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K      Successfully uninstalled wrapt-1.17.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K  Attempting uninstall: websockets━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  4/118\u001b[0m [zipp]\n",
      "\u001b[2K    Found existing installation: websockets 15.0.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/118\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling websockets-15.0.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/118\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled websockets-15.0.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/118\u001b[0m [websockets]\n",
      "\u001b[2K  Attempting uninstall: wcwidth━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/118\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: wcwidth 0.2.14━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [wcwidth]\n",
      "\u001b[2K    Uninstalling wcwidth-0.2.14:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [wcwidth]\n",
      "\u001b[2K      Successfully uninstalled wcwidth-0.2.14━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [wcwidth]\n",
      "\u001b[2K  Attempting uninstall: uv━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [wcwidth]\n",
      "\u001b[2K    Found existing installation: uv 0.9.9━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [wcwidth]\n",
      "\u001b[2K    Uninstalling uv-0.9.9:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [wcwidth]\n",
      "\u001b[2K      Successfully uninstalled uv-0.9.9━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [wcwidth]\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  9/118\u001b[0m [uv]]\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/118\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/118\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/118\u001b[0m [urllib3]\n",
      "\u001b[2K  Attempting uninstall: tzdata━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/118\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: tzdata 2025.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/118\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling tzdata-2025.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/118\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled tzdata-2025.2━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 11/118\u001b[0m [tzdata]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 11/118\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0━━━━━━━━━\u001b[0m \u001b[32m 12/118\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/118\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━━━━━\u001b[0m \u001b[32m 12/118\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: toml━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/118\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: toml 0.10.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/118\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling toml-0.10.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/118\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled toml-0.10.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/118\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tenacity━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]tensions]\n",
      "\u001b[2K    Found existing installation: tenacity 9.1.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K    Uninstalling tenacity-9.1.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K      Successfully uninstalled tenacity-9.1.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K  Attempting uninstall: soupsieve━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K    Found existing installation: soupsieve 2.8━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K    Uninstalling soupsieve-2.8:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K      Successfully uninstalled soupsieve-2.8━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K  Attempting uninstall: sniffio━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 13/118\u001b[0m [toml]\n",
      "\u001b[2K    Found existing installation: sniffio 1.3.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 16/118\u001b[0m [sniffio]\n",
      "\u001b[2K    Uninstalling sniffio-1.3.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 16/118\u001b[0m [sniffio]\n",
      "\u001b[2K      Successfully uninstalled sniffio-1.3.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 16/118\u001b[0m [sniffio]\n",
      "\u001b[2K  Attempting uninstall: sixm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 16/118\u001b[0m [sniffio]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 16/118\u001b[0m [sniffio]\n",
      "\u001b[2K    Uninstalling six-1.17.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 16/118\u001b[0m [sniffio]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: shellingham━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: shellingham 1.5.4━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling shellingham-1.5.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled shellingham-1.5.4━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: pyyaml━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 17/118\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: python-dotenv━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K    Found existing installation: python-dotenv 1.2.1━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K    Uninstalling python-dotenv-1.2.1:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K      Successfully uninstalled python-dotenv-1.2.1━━━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K  Attempting uninstall: pyparsing━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K    Found existing installation: pyparsing 3.2.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K    Uninstalling pyparsing-3.2.5:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K      Successfully uninstalled pyparsing-3.2.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 19/118\u001b[0m [pyyaml]\n",
      "\u001b[2K  Attempting uninstall: pygments0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 21/118\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: Pygments 2.19.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m 21/118\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling Pygments-2.19.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 21/118\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled Pygments-2.19.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 21/118\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: pycparserm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/118\u001b[0m [pygments]\n",
      "\u001b[2K    Found existing installation: pycparser 2.23━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/118\u001b[0m [pygments]\n",
      "\u001b[2K    Uninstalling pycparser-2.23:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/118\u001b[0m [pygments]\n",
      "\u001b[2K      Successfully uninstalled pycparser-2.23━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/118\u001b[0m [pygments]\n",
      "\u001b[2K  Attempting uninstall: protobuf0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/118\u001b[0m [pycparser]\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/118\u001b[0m [pycparser]\n",
      "\u001b[2K    Uninstalling protobuf-6.33.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/118\u001b[0m [pycparser]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/118\u001b[0m [pycparser]\n",
      "\u001b[2K  Attempting uninstall: propcache0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: propcache 0.4.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling propcache-0.4.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled propcache-0.4.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: primp0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: primp 0.15.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling primp-0.15.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled primp-0.15.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/118\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: platformdirs━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K    Found existing installation: platformdirs 4.5.0━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K    Uninstalling platformdirs-4.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K      Successfully uninstalled platformdirs-4.5.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K  Attempting uninstall: pillowm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K    Found existing installation: pillow 12.0.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K    Uninstalling pillow-12.0.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K      Successfully uninstalled pillow-12.0.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/118\u001b[0m [primp]\n",
      "\u001b[2K  Attempting uninstall: packaging90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/118\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/118\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/118\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/118\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: ormsgpack90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: ormsgpack 1.12.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling ormsgpack-1.12.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled ormsgpack-1.12.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: orjson0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: orjson 3.11.4━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling orjson-3.11.4:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled orjson-3.11.4━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-semantic-conventions-ai━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: opentelemetry-semantic-conventions-ai 0.4.1318\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling opentelemetry-semantic-conventions-ai-0.4.13:\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-semantic-conventions-ai-0.4.13/118\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: numpy90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/118\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 33/118\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 33/118\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 33/118\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: mypy-extensions━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 33/118\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: mypy_extensions 1.1.0━━━━━━━━\u001b[0m \u001b[32m 33/118\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling mypy_extensions-1.1.0:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 33/118\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled mypy_extensions-1.1.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 34/118\u001b[0m [mypy-extensions]\n",
      "\u001b[2K  Attempting uninstall: multidictm━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 34/118\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Found existing installation: multidict 6.7.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 34/118\u001b[0m [mypy-extensions]\n",
      "\u001b[2K    Uninstalling multidict-6.7.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 34/118\u001b[0m [mypy-extensions]\n",
      "\u001b[2K      Successfully uninstalled multidict-6.7.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 34/118\u001b[0m [mypy-extensions]\n",
      "\u001b[2K  Attempting uninstall: mdurl\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 35/118\u001b[0m [multidict]s]\n",
      "\u001b[2K    Found existing installation: mdurl 0.1.2━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K    Uninstalling mdurl-0.1.2:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K      Successfully uninstalled mdurl-0.1.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafem━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.3━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.3:m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K  Attempting uninstall: lxml0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K    Found existing installation: lxml 6.0.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K    Uninstalling lxml-6.0.2:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K      Successfully uninstalled lxml-6.0.2━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 36/118\u001b[0m [mdurl]\n",
      "\u001b[2K  Attempting uninstall: kiwisolver\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 38/118\u001b[0m [lxml]\n",
      "\u001b[2K    Found existing installation: kiwisolver 1.4.9━━━━━━━━━━━━━\u001b[0m \u001b[32m 38/118\u001b[0m [lxml]\n",
      "\u001b[2K    Uninstalling kiwisolver-1.4.9:m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 38/118\u001b[0m [lxml]\n",
      "\u001b[2K      Successfully uninstalled kiwisolver-1.4.9━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 39/118\u001b[0m [kiwisolver]\n",
      "\u001b[2K  Attempting uninstall: jsonpointerm━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 39/118\u001b[0m [kiwisolver]\n",
      "\u001b[2K    Found existing installation: jsonpointer 3.0.0━━━━━━━━━━━━\u001b[0m \u001b[32m 39/118\u001b[0m [kiwisolver]\n",
      "\u001b[2K    Uninstalling jsonpointer-3.0.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 39/118\u001b[0m [kiwisolver]\n",
      "\u001b[2K      Successfully uninstalled jsonpointer-3.0.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [jsonpointer]\n",
      "\u001b[2K  Attempting uninstall: jmespath[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Found existing installation: jmespath 1.0.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [jsonpointer]\n",
      "\u001b[2K    Uninstalling jmespath-1.0.1:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/118\u001b[0m [jmespath]\n",
      "\u001b[2K      Successfully uninstalled jmespath-1.0.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/118\u001b[0m [jmespath]\n",
      "\u001b[2K  Attempting uninstall: idna[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/118\u001b[0m [jmespath]\n",
      "\u001b[2K    Found existing installation: idna 3.11━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/118\u001b[0m [jmespath]\n",
      "\u001b[2K    Uninstalling idna-3.11:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/118\u001b[0m [jmespath]\n",
      "\u001b[2K      Successfully uninstalled idna-3.11━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/118\u001b[0m [jmespath]\n",
      "\u001b[2K  Attempting uninstall: httpx-sse90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/118\u001b[0m [jmespath]\n",
      "\u001b[2K    Found existing installation: httpx-sse 0.4.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K    Uninstalling httpx-sse-0.4.3:[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K      Successfully uninstalled httpx-sse-0.4.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K  Attempting uninstall: h11╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K    Found existing installation: h11 0.16.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K    Uninstalling h11-0.16.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K      Successfully uninstalled h11-0.16.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K  Attempting uninstall: greenlet\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K    Found existing installation: greenlet 3.2.4━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K    Uninstalling greenlet-3.2.4:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K      Successfully uninstalled greenlet-3.2.4━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/118\u001b[0m [httpx-sse]\n",
      "\u001b[2K  Attempting uninstall: frozenlist[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K    Found existing installation: frozenlist 1.8.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K    Uninstalling frozenlist-1.8.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K      Successfully uninstalled frozenlist-1.8.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K  Attempting uninstall: frozendict[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K    Found existing installation: frozendict 2.4.7━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K    Uninstalling frozendict-2.4.7:[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K      Successfully uninstalled frozendict-2.4.7━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K  Attempting uninstall: fonttools\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K    Found existing installation: fonttools 4.60.1━━━━━━━━━━━━━\u001b[0m \u001b[32m 45/118\u001b[0m [greenlet]\n",
      "\u001b[2K    Uninstalling fonttools-4.60.1:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/118\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled fonttools-4.60.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/118\u001b[0m [fonttools]\n",
      "\u001b[2K  Attempting uninstall: docstring-parser90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/118\u001b[0m [fonttools]\n",
      "\u001b[2K    Found existing installation: docstring_parser 0.17.0━━━━━━\u001b[0m \u001b[32m 48/118\u001b[0m [fonttools]\n",
      "\u001b[2K    Uninstalling docstring_parser-0.17.0:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/118\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled docstring_parser-0.17.0━━━━━━━━\u001b[0m \u001b[32m 48/118\u001b[0m [fonttools]\n",
      "\u001b[2K  Attempting uninstall: cycler91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: cycler 0.12.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling cycler-0.12.1:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled cycler-0.12.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: click╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: click 8.3.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling click-8.3.1:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled click-8.3.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/118\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.4━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.4:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.4━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: certifi\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: certifi 2025.11.12━━━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling certifi-2025.11.12:[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.11.12━━━━━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: attrsm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: attrs 25.4.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 52/118\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling attrs-25.4.0:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]rmalizer]\n",
      "\u001b[2K      Successfully uninstalled attrs-25.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: annotated-types0m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: annotated-types 0.7.0━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling annotated-types-0.7.0:0m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled annotated-types-0.7.0━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: aiohappyeyeballsm━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: aiohappyeyeballs 2.6.1━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling aiohappyeyeballs-2.6.1:m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled aiohappyeyeballs-2.6.1━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: yarl90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: yarl 1.22.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling yarl-1.22.0:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled yarl-1.22.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 54/118\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: uvicorn\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 57/118\u001b[0m [yarl]\n",
      "\u001b[2K    Found existing installation: uvicorn 0.38.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 57/118\u001b[0m [yarl]\n",
      "\u001b[2K    Uninstalling uvicorn-0.38.0:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 57/118\u001b[0m [yarl]\n",
      "\u001b[2K      Successfully uninstalled uvicorn-0.38.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 57/118\u001b[0m [yarl]\n",
      "\u001b[2K  Attempting uninstall: typing-inspectionm━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 57/118\u001b[0m [yarl]\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.2━━━━━━\u001b[0m \u001b[32m 57/118\u001b[0m [yarl]\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.2:m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 59/118\u001b[0m [typing-inspection]\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.2━━━━━━━━\u001b[0m \u001b[32m 59/118\u001b[0m [typing-inspection]\n",
      "\u001b[2K  Attempting uninstall: typing-inspect\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 59/118\u001b[0m [typing-inspection]\n",
      "\u001b[2K    Found existing installation: typing-inspect 0.9.0━━━━━━━━━\u001b[0m \u001b[32m 59/118\u001b[0m [typing-inspection]\n",
      "\u001b[2K    Uninstalling typing-inspect-0.9.0:\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 59/118\u001b[0m [typing-inspection]\n",
      "\u001b[2K      Successfully uninstalled typing-inspect-0.9.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 60/118\u001b[0m [typing-inspect]\n",
      "\u001b[2K  Attempting uninstall: SQLAlchemy\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 60/118\u001b[0m [typing-inspect]\n",
      "\u001b[2K    Found existing installation: SQLAlchemy 2.0.44━━━━━━━━━━━━\u001b[0m \u001b[32m 60/118\u001b[0m [typing-inspect]\n",
      "\u001b[2K    Uninstalling SQLAlchemy-2.0.44:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 60/118\u001b[0m [typing-inspect]\n",
      "\u001b[2K      Successfully uninstalled SQLAlchemy-2.0.44━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 61/118\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K  Attempting uninstall: requests\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 61/118\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m 61/118\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 61/118\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 61/118\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K  Attempting uninstall: reportlab╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 61/118\u001b[0m [SQLAlchemy]\n",
      "\u001b[2K    Found existing installation: reportlab 4.4.4━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 63/118\u001b[0m [reportlab]\n",
      "\u001b[2K    Uninstalling reportlab-4.4.4:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 63/118\u001b[0m [reportlab]\n",
      "\u001b[2K      Successfully uninstalled reportlab-4.4.4━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 63/118\u001b[0m [reportlab]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 63/118\u001b[0m [reportlab]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0━━\u001b[0m \u001b[32m 63/118\u001b[0m [reportlab]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 63/118\u001b[0m [reportlab]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0━━━━\u001b[0m \u001b[32m 63/118\u001b[0m [reportlab]\n",
      "\u001b[2K  Attempting uninstall: pydantic-corem╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.41.5━━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.41.5:m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.41.5━━━━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K  Attempting uninstall: prompt-toolkitm\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Found existing installation: prompt_toolkit 3.0.52━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Uninstalling prompt_toolkit-3.0.52:\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K      Successfully uninstalled prompt_toolkit-3.0.52━━━━━━━━━━\u001b[0m \u001b[32m 64/118\u001b[0m [python-dateutil]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-protom\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 66/118\u001b[0m [prompt-toolkit]\n",
      "\u001b[2K    Found existing installation: opentelemetry-proto 1.38.0━━━━━━━\u001b[0m \u001b[32m 67/118\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K    Uninstalling opentelemetry-proto-1.38.0:m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 67/118\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-proto-1.38.0━━━━━\u001b[0m \u001b[32m 67/118\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K  Attempting uninstall: marshmallow╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 67/118\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K    Found existing installation: marshmallow 3.26.1━━━━━━━━━━━\u001b[0m \u001b[32m 67/118\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K    Uninstalling marshmallow-3.26.1:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 67/118\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K      Successfully uninstalled marshmallow-3.26.1━━━━━━━━━━━━━\u001b[0m \u001b[32m 67/118\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K  Attempting uninstall: markdown-it-py0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 68/118\u001b[0m [marshmallow]oto]\n",
      "\u001b[2K    Found existing installation: markdown-it-py 4.0.0━━━━━━━━━\u001b[0m \u001b[32m 68/118\u001b[0m [marshmallow]\n",
      "\u001b[2K    Uninstalling markdown-it-py-4.0.0:[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 68/118\u001b[0m [marshmallow]\n",
      "\u001b[2K      Successfully uninstalled markdown-it-py-4.0.0━━━━━━━━━━━\u001b[0m \u001b[32m 68/118\u001b[0m [marshmallow]\n",
      "\u001b[2K  Attempting uninstall: jsonpatch90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 68/118\u001b[0m [marshmallow]\n",
      "\u001b[2K    Found existing installation: jsonpatch 1.33━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 68/118\u001b[0m [marshmallow]\n",
      "\u001b[2K    Uninstalling jsonpatch-1.33:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 68/118\u001b[0m [marshmallow]\n",
      "\u001b[2K      Successfully uninstalled jsonpatch-1.33\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/118\u001b[0m [jsonpatch]\n",
      "\u001b[2K  Attempting uninstall: jinja2m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/118\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/118\u001b[0m [jsonpatch]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/118\u001b[0m [jsonpatch]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.690m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/118\u001b[0m [jsonpatch]\n",
      "\u001b[2K  Attempting uninstall: importlib-metadata\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K    Found existing installation: importlib_metadata 8.7.0━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling importlib_metadata-8.7.0:\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K      Successfully uninstalled importlib_metadata-8.7.0━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K  Attempting uninstall: httpcore\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K    Found existing installation: httpcore 1.0.9━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling httpcore-1.0.9:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K      Successfully uninstalled httpcore-1.0.90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [jinja2]\n",
      "\u001b[2K  Attempting uninstall: googleapis-common-protos90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 73/118\u001b[0m [httpcore]\n",
      "\u001b[2K    Found existing installation: googleapis-common-protos 1.72.00m \u001b[32m 73/118\u001b[0m [httpcore]\n",
      "\u001b[2K    Uninstalling googleapis-common-protos-1.72.0:━━━━━━━━━━━━━\u001b[0m \u001b[32m 73/118\u001b[0m [httpcore]\n",
      "\u001b[2K      Successfully uninstalled googleapis-common-protos-1.72.0\u001b[0m \u001b[32m 73/118\u001b[0m [httpcore]\n",
      "\u001b[2K  Attempting uninstall: duckduckgo-searchm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: duckduckgo_search 8.1.1━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling duckduckgo_search-8.1.1:0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K      Successfully uninstalled duckduckgo_search-8.1.1━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K  Attempting uninstall: contourpy\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: contourpy 1.3.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling contourpy-1.3.3:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K      Successfully uninstalled contourpy-1.3.30m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K  Attempting uninstall: cffi━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: cffi 2.0.0\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 74/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling cffi-2.0.0:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]s-common-protos]\n",
      "\u001b[2K      Successfully uninstalled cffi-2.0.00m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K  Attempting uninstall: beautifulsoup4\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K    Found existing installation: beautifulsoup4 4.14.2━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K    Uninstalling beautifulsoup4-4.14.2:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K      Successfully uninstalled beautifulsoup4-4.14.2━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K  Attempting uninstall: anyio━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K    Found existing installation: anyio 4.11.0[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K    Uninstalling anyio-4.11.0:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K      Successfully uninstalled anyio-4.11.0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/118\u001b[0m [cffi]\n",
      "\u001b[2K  Attempting uninstall: aiosignal━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K    Found existing installation: aiosignal 1.4.0m━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K    Uninstalling aiosignal-1.4.0:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K      Successfully uninstalled aiosignal-1.4.090m━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K  Attempting uninstall: starlettem\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K    Found existing installation: starlette 0.50.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K    Uninstalling starlette-0.50.0:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K      Successfully uninstalled starlette-0.50.00m━━━━━━━━━━━━━\u001b[0m \u001b[32m 79/118\u001b[0m [anyio]\n",
      "\u001b[2K  Attempting uninstall: rich━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m 81/118\u001b[0m [starlette]\n",
      "\u001b[2K    Found existing installation: rich 14.2.0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m 81/118\u001b[0m [starlette]\n",
      "\u001b[2K    Uninstalling rich-14.2.0:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m 81/118\u001b[0m [starlette]\n",
      "\u001b[2K      Successfully uninstalled rich-14.2.0[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m 81/118\u001b[0m [starlette]\n",
      "\u001b[2K  Attempting uninstall: requests-toolbelt91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m 82/118\u001b[0m [rich]]\n",
      "\u001b[2K    Found existing installation: requests-toolbelt 1.0.0━━━━━━━━━━\u001b[0m \u001b[32m 83/118\u001b[0m [requests-toolbelt]\n",
      "\u001b[2K    Uninstalling requests-toolbelt-1.0.0:╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 83/118\u001b[0m [requests-toolbelt]\n",
      "\u001b[2K      Successfully uninstalled requests-toolbelt-1.0.0━━━━━━━━\u001b[0m \u001b[32m 83/118\u001b[0m [requests-toolbelt]\n",
      "\u001b[2K  Attempting uninstall: pydantic\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 83/118\u001b[0m [requests-toolbelt]\n",
      "\u001b[2K    Found existing installation: pydantic 2.12.490m━━━━━━━━━━━\u001b[0m \u001b[32m 83/118\u001b[0m [requests-toolbelt]\n",
      "\u001b[2K    Uninstalling pydantic-2.12.4:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 83/118\u001b[0m [requests-toolbelt]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.12.4\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 83/118\u001b[0m [requests-toolbelt]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 84/118\u001b[0m [pydantic]belt]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 84/118\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.3[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-exporter-otlp-proto-common━━\u001b[0m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.38.0[0m [pandas]\n",
      "\u001b[2K    Uninstalling opentelemetry-exporter-otlp-proto-common-1.38.0:m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.38.08\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-api╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: opentelemetry-api 1.38.0━━━━━\u001b[0m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling opentelemetry-api-1.38.0:\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-api-1.38.0━━━━━━━\u001b[0m \u001b[32m 85/118\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: matplotlib━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 87/118\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.70m━━━━━━━━━━\u001b[0m \u001b[32m 87/118\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.7:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 87/118\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.7[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]pi]\n",
      "\u001b[2K  Attempting uninstall: httpx━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: httpx 0.28.10m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling httpx-0.28.1:━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]\n",
      "\u001b[2K      Successfully uninstalled httpx-0.28.1\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: dataclasses-json1m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: dataclasses-json 0.6.7━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling dataclasses-json-0.6.7:1m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 88/118\u001b[0m [matplotlib]\n",
      "\u001b[2K      Successfully uninstalled dataclasses-json-0.6.7[90m━━━━━━━━━\u001b[0m \u001b[32m 90/118\u001b[0m [dataclasses-json]\n",
      "\u001b[2K  Attempting uninstall: curl_cffi━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 90/118\u001b[0m [dataclasses-json]\n",
      "\u001b[2K    Found existing installation: curl_cffi 0.13.0[90m━━━━━━━━━\u001b[0m \u001b[32m 90/118\u001b[0m [dataclasses-json]\n",
      "\u001b[2K    Uninstalling curl_cffi-0.13.0:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 90/118\u001b[0m [dataclasses-json]\n",
      "\u001b[2K      Successfully uninstalled curl_cffi-0.13.0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 90/118\u001b[0m [dataclasses-json]\n",
      "\u001b[2K  Attempting uninstall: botocore━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 91/118\u001b[0m [curl_cffi]on]\n",
      "\u001b[2K    Found existing installation: botocore 1.40.74[90m━━━━━━━━━\u001b[0m \u001b[32m 91/118\u001b[0m [curl_cffi]\n",
      "\u001b[2K    Uninstalling botocore-1.40.74:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 92/118\u001b[0m [botocore]\n",
      "\u001b[2K      Successfully uninstalled botocore-1.40.740m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 92/118\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: aiohttp━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 92/118\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: aiohttp 3.13.20m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 92/118\u001b[0m [botocore]\n",
      "\u001b[2K    Uninstalling aiohttp-3.13.2:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 92/118\u001b[0m [botocore]\n",
      "\u001b[2K      Successfully uninstalled aiohttp-3.13.2\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 92/118\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: yfinance━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 93/118\u001b[0m [aiohttp]\n",
      "\u001b[2K    Found existing installation: yfinance 0.2.66m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 93/118\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling yfinance-0.2.66:━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 93/118\u001b[0m [aiohttp]\n",
      "\u001b[2K      Successfully uninstalled yfinance-0.2.66[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 93/118\u001b[0m [aiohttp]\n",
      "\u001b[2K  Attempting uninstall: typer━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [yfinance]\n",
      "\u001b[2K    Found existing installation: typer 0.20.0\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [yfinance]\n",
      "\u001b[2K    Uninstalling typer-0.20.0:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [yfinance]\n",
      "\u001b[2K      Successfully uninstalled typer-0.20.0m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [yfinance]\n",
      "\u001b[2K  Attempting uninstall: seaborn━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [yfinance]\n",
      "\u001b[2K    Found existing installation: seaborn 0.13.20m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [yfinance]\n",
      "\u001b[2K    Uninstalling seaborn-0.13.2:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 96/118\u001b[0m [seaborn]\n",
      "\u001b[2K      Successfully uninstalled seaborn-0.13.2╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 96/118\u001b[0m [seaborn]\n",
      "\u001b[2K  Attempting uninstall: s3transfer━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 96/118\u001b[0m [seaborn]\n",
      "\u001b[2K    Found existing installation: s3transfer 0.14.0\u001b[90m━━━━━━━\u001b[0m \u001b[32m 96/118\u001b[0m [seaborn]\n",
      "\u001b[2K    Uninstalling s3transfer-0.14.0:━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 96/118\u001b[0m [seaborn]\n",
      "\u001b[2K      Successfully uninstalled s3transfer-0.14.00m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 96/118\u001b[0m [seaborn]\n",
      "\u001b[2K  Attempting uninstall: pydantic-settings[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 96/118\u001b[0m [seaborn]\n",
      "\u001b[2K    Found existing installation: pydantic-settings 2.12.090m━━━━━━\u001b[0m \u001b[32m 98/118\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Uninstalling pydantic-settings-2.12.0:[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m 98/118\u001b[0m [pydantic-settings]\n",
      "\u001b[2K      Successfully uninstalled pydantic-settings-2.12.0m━━━━━━\u001b[0m \u001b[32m 98/118\u001b[0m [pydantic-settings]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-semantic-conventions━━━━\u001b[0m \u001b[32m 98/118\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Found existing installation: opentelemetry-semantic-conventions 0.59b08/118\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Uninstalling opentelemetry-semantic-conventions-0.59b0:━━━\u001b[0m \u001b[32m 98/118\u001b[0m [pydantic-settings]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-semantic-conventions-0.59b0 98/118\u001b[0m [pydantic-settings]\n",
      "\u001b[2K  Attempting uninstall: langsmith━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 99/118\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Found existing installation: langsmith 0.4.43━━━━━\u001b[0m \u001b[32m 99/118\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Uninstalling langsmith-0.4.43:\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 99/118\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.4.430m━━━━━\u001b[0m \u001b[32m 99/118\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K  Attempting uninstall: langgraph-sdk━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [langsmith]-conventions]\n",
      "\u001b[2K    Found existing installation: langgraph-sdk 0.2.9[90m━━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [langsmith]\n",
      "\u001b[2K    Uninstalling langgraph-sdk-0.2.9:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [langsmith]\n",
      "\u001b[2K      Successfully uninstalled langgraph-sdk-0.2.9m\u001b[90m━━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [langsmith]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-sdk\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [langsmith]\n",
      "\u001b[2K    Found existing installation: opentelemetry-sdk 1.38.0━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [langsmith]\n",
      "\u001b[2K    Uninstalling opentelemetry-sdk-1.38.0:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m102/118\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-sdk-1.38.00m━━━━━\u001b[0m \u001b[32m102/118\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-instrumentation[90m━━━━━\u001b[0m \u001b[32m102/118\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K    Found existing installation: opentelemetry-instrumentation 0.59b032m102/118\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K    Uninstalling opentelemetry-instrumentation-0.59b0:90m━━━━━\u001b[0m \u001b[32m102/118\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-instrumentation-0.59b0\u001b[32m102/118\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K  Attempting uninstall: langchain-core━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m103/118\u001b[0m [opentelemetry-instrumentation]\n",
      "\u001b[2K    Found existing installation: langchain-core 1.0.50m━━━━\u001b[0m \u001b[32m103/118\u001b[0m [opentelemetry-instrumentation]\n",
      "\u001b[2K    Uninstalling langchain-core-1.0.5:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m103/118\u001b[0m [opentelemetry-instrumentation]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-1.0.5[90m━━━━\u001b[0m \u001b[32m103/118\u001b[0m [opentelemetry-instrumentation]\n",
      "\u001b[2K  Attempting uninstall: boto3━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m104/118\u001b[0m [langchain-core]ntation]\n",
      "\u001b[2K    Found existing installation: boto3 1.40.74m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m105/118\u001b[0m [boto3]core]\n",
      "\u001b[2K    Uninstalling boto3-1.40.74:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m105/118\u001b[0m [boto3]\n",
      "\u001b[2K      Successfully uninstalled boto3-1.40.74[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m105/118\u001b[0m [boto3]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-instrumentation-langchain[0m \u001b[32m105/118\u001b[0m [boto3]\n",
      "\u001b[2K    Found existing installation: opentelemetry-instrumentation-langchain 0.48.0\u001b[0m [boto3]\n",
      "\u001b[2K    Uninstalling opentelemetry-instrumentation-langchain-0.48.0:0m \u001b[32m105/118\u001b[0m [boto3]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-instrumentation-langchain-0.48.018\u001b[0m [boto3]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-exporter-otlp-proto-http\u001b[0m \u001b[32m105/118\u001b[0m [boto3]\n",
      "\u001b[2K    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.38.0pentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K    Uninstalling opentelemetry-exporter-otlp-proto-http-1.38.0:/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.38.0ntelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K  Attempting uninstall: langgraph-checkpoint[90m━━\u001b[0m \u001b[32m107/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K    Found existing installation: langgraph-checkpoint 3.0.1m107/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K    Uninstalling langgraph-checkpoint-3.0.1:[90m━━\u001b[0m \u001b[32m107/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K      Successfully uninstalled langgraph-checkpoint-3.0.132m107/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splitters━━\u001b[0m \u001b[32m107/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 1.0.0/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-1.0.0:━━\u001b[0m \u001b[32m107/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-1.0.007/118\u001b[0m [opentelemetry-exporter-otlp-proto-http]\n",
      "\u001b[2K  Attempting uninstall: langchain-aws━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m109/118\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K    Found existing installation: langchain-aws 1.0.00m\u001b[90m━━━\u001b[0m \u001b[32m109/118\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K    Uninstalling langchain-aws-1.0.0:━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m109/118\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K      Successfully uninstalled langchain-aws-1.0.0\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m109/118\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K  Attempting uninstall: bedrock-agentcore━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m110/118\u001b[0m [langchain-aws]itters]\n",
      "\u001b[2K    Found existing installation: bedrock-agentcore 1.0.6[90m━━\u001b[0m \u001b[32m110/118\u001b[0m [langchain-aws]\n",
      "\u001b[2K    Uninstalling bedrock-agentcore-1.0.6:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m110/118\u001b[0m [langchain-aws]\n",
      "\u001b[2K      Successfully uninstalled bedrock-agentcore-1.0.6m\u001b[90m━━\u001b[0m \u001b[32m110/118\u001b[0m [langchain-aws]\n",
      "\u001b[2K  Attempting uninstall: langgraph-prebuilt[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m110/118\u001b[0m [langchain-aws]\n",
      "\u001b[2K    Found existing installation: langgraph-prebuilt 1.0.40m\u001b[90m━━\u001b[0m \u001b[32m112/118\u001b[0m [langgraph-prebuilt]\n",
      "\u001b[2K    Uninstalling langgraph-prebuilt-1.0.4:[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112/118\u001b[0m [langgraph-prebuilt]\n",
      "\u001b[2K      Successfully uninstalled langgraph-prebuilt-1.0.4\u001b[90m━━\u001b[0m \u001b[32m112/118\u001b[0m [langgraph-prebuilt]\n",
      "\u001b[2K  Attempting uninstall: langchain-classic\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112/118\u001b[0m [langgraph-prebuilt]\n",
      "\u001b[2K    Found existing installation: langchain-classic 1.0.0[90m━━\u001b[0m \u001b[32m112/118\u001b[0m [langgraph-prebuilt]\n",
      "\u001b[2K    Uninstalling langchain-classic-1.0.0:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m113/118\u001b[0m [langchain-classic]\n",
      "\u001b[2K      Successfully uninstalled langchain-classic-1.0.00m\u001b[90m━\u001b[0m \u001b[32m113/118\u001b[0m [langchain-classic]\n",
      "\u001b[2K  Attempting uninstall: bedrock-agentcore-starter-toolkit[0m\u001b[90m━\u001b[0m \u001b[32m113/118\u001b[0m [langchain-classic]\n",
      "\u001b[2K    Found existing installation: bedrock-agentcore-starter-toolkit 0.1.1113/118\u001b[0m [langchain-classic]\n",
      "\u001b[2K    Uninstalling bedrock-agentcore-starter-toolkit-0.1.1:[90m━\u001b[0m \u001b[32m113/118\u001b[0m [langchain-classic]\n",
      "\u001b[2K      Successfully uninstalled bedrock-agentcore-starter-toolkit-0.1.12m113/118\u001b[0m [langchain-classic]\n",
      "\u001b[2K  Attempting uninstall: langgraph━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m114/118\u001b[0m [bedrock-agentcore-starter-toolkit]\n",
      "\u001b[2K    Found existing installation: langgraph 1.0.3m\u001b[90m━\u001b[0m \u001b[32m114/118\u001b[0m [bedrock-agentcore-starter-toolkit]\n",
      "\u001b[2K    Uninstalling langgraph-1.0.3:━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m114/118\u001b[0m [bedrock-agentcore-starter-toolkit]\n",
      "\u001b[2K      Successfully uninstalled langgraph-1.0.3[0m\u001b[90m━\u001b[0m \u001b[32m114/118\u001b[0m [bedrock-agentcore-starter-toolkit]\n",
      "\u001b[2K  Attempting uninstall: langchain-community━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m115/118\u001b[0m [langgraph]rter-toolkit]\n",
      "\u001b[2K    Found existing installation: langchain-community 0.4.190m━\u001b[0m \u001b[32m115/118\u001b[0m [langgraph]\n",
      "\u001b[2K    Uninstalling langchain-community-0.4.1:━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m116/118\u001b[0m [langchain-community]\n",
      "\u001b[2K      Successfully uninstalled langchain-community-0.4.1m \u001b[32m116/118\u001b[0m [langchain-community]\n",
      "\u001b[2K  Attempting uninstall: langchain━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m116/118\u001b[0m [langchain-community]\n",
      "\u001b[2K    Found existing installation: langchain 1.0.7[90m╺\u001b[0m \u001b[32m116/118\u001b[0m [langchain-community]\n",
      "\u001b[2K    Uninstalling langchain-1.0.7:━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m116/118\u001b[0m [langchain-community]\n",
      "\u001b[2K      Successfully uninstalled langchain-1.0.7m\u001b[90m╺\u001b[0m \u001b[32m116/118\u001b[0m [langchain-community]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118/118\u001b[0m [langchain]hain-community]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.4.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.31.6 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.22.0 requires botocore<1.37.4,>=1.37.2, but you have botocore 1.40.74 which is incompatible.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.2.8 requires numpy<=2.0.1, but you have numpy 2.3.5 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.4 requires numpy<2, but you have numpy 2.3.5 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires Pillow<12,>=10.0.1, but you have pillow 12.0.0 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.1 which is incompatible.\n",
      "autogluon-timeseries 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.1 which is incompatible.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.3.5 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.2 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "fastapi 0.120.1 requires starlette<0.50.0,>=0.40.0, but you have starlette 0.50.0 which is incompatible.\n",
      "gluonts 0.16.2 requires numpy<2.2,>=1.16, but you have numpy 2.3.5 which is incompatible.\n",
      "jupyter-ai-magics 2.31.6 requires langchain<0.4.0,>=0.3.0, but you have langchain 1.0.7 which is incompatible.\n",
      "jupyter-ai-magics 2.31.6 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.4.1 which is incompatible.\n",
      "jupyter-scheduler 2.11.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.2 which is incompatible.\n",
      "mlflow 2.22.0 requires packaging<25, but you have packaging 25.0 which is incompatible.\n",
      "mlflow-skinny 2.22.0 requires packaging<25, but you have packaging 25.0 which is incompatible.\n",
      "opentelemetry-instrumentation-threading 0.57b0 requires opentelemetry-instrumentation==0.57b0, but you have opentelemetry-instrumentation 0.59b0 which is incompatible.\n",
      "sagemaker 2.245.0 requires attrs<24,>=23.1.0, but you have attrs 25.4.0 which is incompatible.\n",
      "sagemaker 2.245.0 requires importlib-metadata<7.0,>=1.4.0, but you have importlib-metadata 8.7.0 which is incompatible.\n",
      "sagemaker 2.245.0 requires numpy==1.26.4, but you have numpy 2.3.5 which is incompatible.\n",
      "sagemaker 2.245.0 requires packaging<25,>=23.0, but you have packaging 25.0 which is incompatible.\n",
      "sagemaker 2.245.0 requires protobuf<6.0,>=3.12, but you have protobuf 6.33.1 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.2 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\n",
      "snowflake-connector-python 3.17.4 requires cffi<2.0.0,>=1.9, but you have cffi 2.0.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\n",
      "strands-agents-tools 0.1.9 requires pillow<12.0.0,>=11.2.1, but you have pillow 12.0.0 which is incompatible.\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 beautifulsoup4-4.14.2 bedrock-agentcore-1.0.6 bedrock-agentcore-starter-toolkit-0.1.1 boto3-1.40.74 botocore-1.40.74 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 contourpy-1.3.3 curl_cffi-0.13.0 cycler-0.12.1 dataclasses-json-0.6.7 docstring-parser-0.17.0 duckduckgo-search-8.1.1 fonttools-4.60.1 frozendict-2.4.7 frozenlist-1.8.0 googleapis-common-protos-1.72.0 greenlet-3.2.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 idna-3.11 importlib-metadata-8.7.0 jinja2-3.1.6 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 kiwisolver-1.4.9 langchain-1.0.7 langchain-aws-1.0.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.5 langchain-text-splitters-1.0.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 langsmith-0.4.43 lxml-6.0.2 markdown-it-py-4.0.0 marshmallow-3.26.1 matplotlib-3.10.7 mdurl-0.1.2 multidict-6.7.0 multitasking-0.0.12 mypy-extensions-1.1.0 numpy-2.3.5 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-langchain-0.48.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 opentelemetry-semantic-conventions-ai-0.4.13 orjson-3.11.4 ormsgpack-1.12.0 packaging-25.0 pandas-2.3.3 peewee-3.18.3 pillow-12.0.0 platformdirs-4.5.0 primp-0.15.0 prompt-toolkit-3.0.52 propcache-0.4.1 protobuf-6.33.1 pycparser-2.23 pydantic-2.12.4 pydantic-core-2.41.5 pydantic-settings-2.12.0 pygments-2.19.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 reportlab-4.4.4 requests-2.32.5 requests-toolbelt-1.0.0 rich-14.2.0 s3transfer-0.14.0 seaborn-0.13.2 shellingham-1.5.4 six-1.17.0 sniffio-1.3.1 soupsieve-2.8 starlette-0.50.0 tenacity-9.1.2 toml-0.10.2 typer-0.20.0 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uv-0.9.9 uvicorn-0.38.0 wcwidth-0.2.14 websockets-15.0.1 wrapt-1.17.3 xxhash-3.6.0 yarl-1.22.0 yfinance-0.2.66 zipp-3.23.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46656a28-239b-4644-a5c1-dbcb52292e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_endpoint_name = \"glm4-5-2025-11-05-23-19-04-348\"\n",
    "assert sagemaker_endpoint_name != \"\"\n",
    "\n",
    "bucket_name = \"glm-45-agentic-demo\"\n",
    "assert bucket_name != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7df68-b447-44bb-b7a4-c63204abe429",
   "metadata": {},
   "source": [
    "## Prerequisites: Deploy GLM 4.5 Model on Amazon SageMaker\n",
    "\n",
    "Before we begin building our stock analyzer agent, you'll need to deploy the GLM 4.5 model using Amazon SageMaker AI from Hugging Face.\n",
    "\n",
    "**Required Setup:**\n",
    "1. Open the notebook `GLM-4.5.ipynb` in the `./deploy_sagemaker/gpt-oss` folder\n",
    "2. Follow the instructions to deploy the GLM model from Hugging Face to a SageMaker endpoint\n",
    "3. Note down the **endpoint name** that gets created (you'll need this for our agent configuration)\n",
    "4. Return to this notebook once your SageMaker endpoint is successfully deployed\n",
    "\n",
    "The SageMaker endpoint will serve as the language model backend for our intelligent stock analyzer agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## Creating your agents and experimenting locally\n",
    "\n",
    "Before we deploy our agents to AgentCore Runtime, let's develop and run them locally for experimentation purposes.\n",
    "\n",
    "For production agentic applications we will need to decouple the agent creation process from the agent invocation one. With AgentCore Runtime, we will decorate the invocation part of our agent with the `@app.entrypoint` decorator and have it as the entry point for our runtime. Let's first look how each agent is developed during the experimentation phase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746613e3-a14b-4653-81cb-741f23903427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created langgraph_stock_local.py with endpoint: glm4-5-2025-11-05-23-19-04-348\n"
     ]
    }
   ],
   "source": [
    "def create_local_stock_agent_file(endpoint_name, filename=\"langgraph_stock_local.py\"):\n",
    "    \"\"\"\n",
    "    Create a local stock analysis agent file with the specified SageMaker endpoint name\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name: SageMaker endpoint name to use\n",
    "        filename: Output filename (default: langgraph_stock_local.py)\n",
    "    \"\"\"\n",
    "    \n",
    "    code_content = f'''from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_aws.llms import SagemakerEndpoint\n",
    "from langchain_aws.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import argparse\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib import colors\n",
    "import os\n",
    "\n",
    "# Create stock analysis tools\n",
    "@tool\n",
    "def gather_stock_data(stock_symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Gather comprehensive stock data from various sources including price history, \n",
    "    financial metrics, news, and market data.\n",
    "    \n",
    "    Args:\n",
    "        stock_symbol: Stock ticker symbol (e.g., 'AMZN', 'GOOGL', 'TSLA')\n",
    "    \n",
    "    Returns:\n",
    "        Comprehensive stock data including current price, historical performance, \n",
    "        financial metrics, and recent news\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the stock symbol\n",
    "        symbol = stock_symbol.upper().strip()\n",
    "        \n",
    "        # Get stock data using yfinance\n",
    "        stock = yf.Ticker(symbol)\n",
    "        \n",
    "        # Get basic info\n",
    "        info = stock.info\n",
    "        \n",
    "        # Get historical data (1 year)\n",
    "        hist = stock.history(period=\"1y\")\n",
    "        current_price = hist['Close'].iloc[-1] if not hist.empty else 0\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        if len(hist) > 0:\n",
    "            year_high = hist['High'].max()\n",
    "            year_low = hist['Low'].min()\n",
    "            year_start_price = hist['Close'].iloc[0]\n",
    "            ytd_return = ((current_price - year_start_price) / year_start_price) * 100\n",
    "            \n",
    "            # Calculate volatility (standard deviation of daily returns)\n",
    "            daily_returns = hist['Close'].pct_change().dropna()\n",
    "            volatility = daily_returns.std() * (252 ** 0.5) * 100  # Annualized volatility\n",
    "        else:\n",
    "            year_high = year_low = ytd_return = volatility = 0\n",
    "            \n",
    "        # Get recent news (simulated - in production you'd use a real news API)\n",
    "        recent_news = [\n",
    "            f\"{{symbol}} reports quarterly earnings with mixed results\",\n",
    "            f\"Analysts upgrade {{symbol}} price target amid strong fundamentals\",\n",
    "            f\"{{symbol}} announces new strategic partnership\",\n",
    "            f\"Market volatility affects {{symbol}} trading volume\"\n",
    "        ]\n",
    "        \n",
    "        # Format the comprehensive data\n",
    "        stock_data = f\"\"\"STOCK DATA GATHERING REPORT:\n",
    "================================\n",
    "Stock Symbol: {{symbol}}\n",
    "Company Name: {{info.get('longName', 'N/A')}}\n",
    "Sector: {{info.get('sector', 'N/A')}}\n",
    "Industry: {{info.get('industry', 'N/A')}}\n",
    "\n",
    "CURRENT MARKET DATA:\n",
    "- Current Price: ${{current_price:.2f}}\n",
    "- Market Cap: ${{info.get('marketCap', 0):,}} \n",
    "- 52-Week High: ${{year_high:.2f}}\n",
    "- 52-Week Low: ${{year_low:.2f}}\n",
    "- YTD Return: {{ytd_return:.2f}}%\n",
    "- Volatility (Annualized): {{volatility:.2f}}%\n",
    "\n",
    "FINANCIAL METRICS:\n",
    "- P/E Ratio: {{info.get('trailingPE', 'N/A')}}\n",
    "- Forward P/E: {{info.get('forwardPE', 'N/A')}}\n",
    "- Price-to-Book: {{info.get('priceToBook', 'N/A')}}\n",
    "- Dividend Yield: {{info.get('dividendYield', 0) * 100 if info.get('dividendYield') else 0:.2f}}%\n",
    "- Revenue (TTM): ${{info.get('totalRevenue', 0):,}}\n",
    "- Profit Margin: {{info.get('profitMargins', 0) * 100 if info.get('profitMargins') else 0:.2f}}%\n",
    "\n",
    "TRADING METRICS:\n",
    "- Average Volume: {{info.get('averageVolume', 0):,}}\n",
    "- Beta: {{info.get('beta', 'N/A')}}\n",
    "- EPS (TTM): ${{info.get('trailingEps', 'N/A')}}\n",
    "- Book Value: ${{info.get('bookValue', 'N/A')}}\n",
    "\n",
    "RECENT NEWS HEADLINES:\n",
    "{{chr(10).join(f\"- {{news}}\" for news in recent_news)}}\n",
    "\n",
    "DATA COLLECTION TIMESTAMP: {{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}}\n",
    "\"\"\"\n",
    "        \n",
    "        return stock_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"\"\"STOCK DATA GATHERING ERROR:\n",
    "================================\n",
    "Stock Symbol: {{stock_symbol}}\n",
    "Error: Unable to gather comprehensive stock data\n",
    "Details: {{str(e)}}\n",
    "\n",
    "Please verify the stock symbol is correct and try again.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def analyze_stock_performance(stock_data: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze stock performance based on gathered data, providing technical analysis,\n",
    "    fundamental analysis, and risk assessment WITHOUT investment recommendations.\n",
    "    \n",
    "    Args:\n",
    "        stock_data: Raw stock data from the data gathering agent\n",
    "    \n",
    "    Returns:\n",
    "        Comprehensive stock analysis including technical indicators, fundamental analysis,\n",
    "        and risk assessment for informational purposes only\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extract key metrics from stock data\n",
    "    symbol_match = re.search(r'Stock Symbol: ([A-Z]+)', stock_data)\n",
    "    price_match = re.search(r'Current Price: \\\\$([\\\\d.]+)', stock_data)\n",
    "    pe_match = re.search(r'P/E Ratio: ([\\\\d.]+)', stock_data)\n",
    "    ytd_match = re.search(r'YTD Return: ([\\\\d.-]+)%', stock_data)\n",
    "    volatility_match = re.search(r'Volatility \\\\(Annualized\\\\): ([\\\\d.]+)%', stock_data)\n",
    "    dividend_match = re.search(r'Dividend Yield: ([\\\\d.]+)%', stock_data)\n",
    "    beta_match = re.search(r'Beta: ([\\\\d.]+)', stock_data)\n",
    "    profit_margin_match = re.search(r'Profit Margin: ([\\\\d.]+)%', stock_data)\n",
    "    \n",
    "    symbol = symbol_match.group(1) if symbol_match else 'UNKNOWN'\n",
    "    current_price = float(price_match.group(1)) if price_match else 0\n",
    "    pe_ratio = float(pe_match.group(1)) if pe_match and pe_match.group(1) != 'N/A' else None\n",
    "    ytd_return = float(ytd_match.group(1)) if ytd_match else 0\n",
    "    volatility = float(volatility_match.group(1)) if volatility_match else 0\n",
    "    dividend_yield = float(dividend_match.group(1)) if dividend_match else 0\n",
    "    beta = float(beta_match.group(1)) if beta_match and beta_match.group(1) != 'N/A' else None\n",
    "    profit_margin = float(profit_margin_match.group(1)) if profit_margin_match else 0\n",
    "    risk_level = \"MEDIUM\"\n",
    "    risk_description = \"MEDIUM Risk\"\n",
    "    \n",
    "    # Technical Analysis (descriptive only)\n",
    "    if ytd_return > 20:\n",
    "        price_trend = \"STRONG UPTREND\"\n",
    "    elif ytd_return > 10:\n",
    "        price_trend = \"MODERATE UPTREND\"\n",
    "    elif ytd_return > 0:\n",
    "        price_trend = \"SLIGHT UPTREND\"\n",
    "    elif ytd_return > -10:\n",
    "        price_trend = \"SLIGHT DOWNTREND\"\n",
    "    else:\n",
    "        price_trend = \"STRONG DOWNTREND\"\n",
    "    \n",
    "    # Fundamental Analysis (descriptive only)\n",
    "    fundamental_factors = []\n",
    "    \n",
    "    if pe_ratio:\n",
    "        if pe_ratio < 15:\n",
    "            fundamental_factors.append(\"P/E ratio suggests potential undervaluation\")\n",
    "        elif pe_ratio < 25:\n",
    "            fundamental_factors.append(\"P/E ratio within reasonable range\")\n",
    "        else:\n",
    "            fundamental_factors.append(\"P/E ratio suggests potential overvaluation\")\n",
    "    \n",
    "    if profit_margin > 20:\n",
    "        fundamental_factors.append(\"Excellent profit margins\")\n",
    "    elif profit_margin > 10:\n",
    "        fundamental_factors.append(\"Good profit margins\")\n",
    "    else:\n",
    "        fundamental_factors.append(\"Low profit margins\")\n",
    "    \n",
    "    if dividend_yield > 3:\n",
    "        fundamental_factors.append(\"High dividend yield\")\n",
    "    elif dividend_yield > 1:\n",
    "        fundamental_factors.append(\"Moderate dividend yield\")\n",
    "    else:\n",
    "        fundamental_factors.append(\"Low or no dividend yield\")\n",
    "    \n",
    "    beta_description = \"\"\n",
    "    if beta and beta > 1.5:\n",
    "        beta_description = \"High beta indicates sensitivity to market movements\"\n",
    "    elif beta and beta < 0.5:\n",
    "        beta_description = \"Low beta indicates stability relative to market\"\n",
    "    else:\n",
    "        beta_description = \"Beta indicates moderate market correlation\"\n",
    "    \n",
    "    analysis_report = f\"\"\"STOCK PERFORMANCE ANALYSIS:\n",
    "===============================\n",
    "Stock: {{symbol}} | Current Price: ${{current_price:.2f}}\n",
    "\n",
    "\n",
    "TECHNICAL ANALYSIS:\n",
    "- Price Trend: {{price_trend}}\n",
    "- YTD Performance: {{ytd_return:.2f}}%\n",
    "- Volatility Level: {{volatility:.2f}}% ({{risk_level}} RISK)\n",
    "- Volatility Assessment: {{risk_description}}\n",
    "\n",
    "FUNDAMENTAL ANALYSIS:\n",
    "- P/E Ratio: {{pe_ratio if pe_ratio else 'N/A'}}\n",
    "- Profit Margin: {{profit_margin:.2f}}%\n",
    "- Dividend Yield: {{dividend_yield:.2f}}%\n",
    "- Beta: {{beta if beta else 'N/A'}}\n",
    "\n",
    "KEY OBSERVATIONS:\n",
    "{{chr(10).join(f\"• {{factor}}\" for factor in fundamental_factors)}}\n",
    "\n",
    "\n",
    "ANALYST SUMMARY:\n",
    "Based on technical and fundamental analysis, {{symbol}} shows {{price_trend.lower()}} with {{risk_level.lower()}} volatility profile. \n",
    "The analysis reflects current market conditions and financial performance metrics for informational purposes.\n",
    "\n",
    "DISCLAIMER: This analysis is for informational purposes only and does not constitute investment advice.\n",
    "\"\"\"\n",
    "    \n",
    "    return analysis_report\n",
    "\n",
    "@tool\n",
    "def generate_stock_report(stock_data: str, analysis_data: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive stock report based on gathered data and analysis.\n",
    "    Creates a professional PDF report for documentation purposes.\n",
    "    \n",
    "    Args:\n",
    "        stock_data: Raw stock data from the data gathering agent\n",
    "        analysis_data: Analysis results from the performance analyzer\n",
    "    \n",
    "    Returns:\n",
    "        Report generation summary with PDF creation status\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extract key information for report\n",
    "    symbol_match = re.search(r'Stock Symbol: ([A-Z]+)', stock_data)\n",
    "    price_match = re.search(r'Current Price: \\\\$([\\\\d.]+)', stock_data)\n",
    "    company_match = re.search(r'Company Name: ([^\\\\n]+)', stock_data)\n",
    "    sector_match = re.search(r'Sector: ([^\\\\n]+)', stock_data)\n",
    "    ytd_match = re.search(r'YTD Performance: ([\\\\d.-]+)%', analysis_data)\n",
    "    risk_match = re.search(r'Volatility Risk: ([A-Z]+)', analysis_data)\n",
    "    \n",
    "    symbol = symbol_match.group(1) if symbol_match else 'UNKNOWN'\n",
    "    current_price = float(price_match.group(1)) if price_match else 0\n",
    "    company_name = company_match.group(1).strip() if company_match else 'N/A'\n",
    "    sector = sector_match.group(1).strip() if sector_match else 'N/A'\n",
    "    ytd_performance = float(ytd_match.group(1)) if ytd_match else 0\n",
    "    risk_level = risk_match.group(1) if risk_match else 'MEDIUM'\n",
    "    risk_level  = 'MEDIUM'\n",
    "    \n",
    "    # Generate PDF report filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    pdf_filename = f\"{{symbol}}_Stock_Report_{{timestamp}}.pdf\"\n",
    "    \n",
    "    # Create PDF report\n",
    "    try:\n",
    "        create_stock_report_pdf(symbol, company_name, sector, current_price, \n",
    "                              ytd_performance, risk_level, stock_data, analysis_data, pdf_filename)\n",
    "        pdf_status = f\"PDF report generated: {{pdf_filename}}\"\n",
    "    except Exception as e:\n",
    "        pdf_status = f\"PDF generation failed: {{str(e)}}\"\n",
    "    \n",
    "    report_summary = f\"\"\"STOCK REPORT GENERATION:\n",
    "===============================\n",
    "Stock: {{symbol}} ({{company_name}})\n",
    "Sector: {{sector}}\n",
    "Current Price: ${{current_price:.2f}}\n",
    "\n",
    "REPORT SUMMARY:\n",
    "- Technical Analysis: {{ytd_performance:.2f}}% YTD performance\n",
    "- Risk Assessment: {{risk_level}} volatility risk\n",
    "- Report Type: Comprehensive stock analysis for informational purposes\n",
    "- Generated: {{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}}\n",
    "\n",
    "{{pdf_status}}\n",
    "\n",
    "REPORT CONTENTS:\n",
    "• Executive Summary with key metrics\n",
    "• Detailed market data and financial metrics\n",
    "• Technical and fundamental analysis\n",
    "• Risk assessment and observations\n",
    "• Professional formatting for documentation\n",
    "\n",
    "DISCLAIMER: This report is for informational and educational purposes only. \n",
    "It does not constitute investment advice or recommendations.\n",
    "\"\"\"\n",
    "    \n",
    "    return report_summary\n",
    "\n",
    "def create_stock_report_pdf(symbol, company_name, sector, price, ytd_perf, risk_level, stock_data, analysis_data, filename):\n",
    "    \"\"\"Create a professional PDF stock report\"\"\"\n",
    "    doc = SimpleDocTemplate(filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "    \n",
    "    # Title\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=18,\n",
    "        spaceAfter=30,\n",
    "        textColor=colors.darkblue\n",
    "    )\n",
    "    story.append(Paragraph(f\"Stock Analysis Report: {{symbol}}\", title_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Executive Summary\n",
    "    story.append(Paragraph(\"Executive Summary\", styles['Heading2']))\n",
    "    summary_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Stock Symbol', symbol],\n",
    "        ['Company Name', company_name],\n",
    "        ['Sector', sector],\n",
    "        ['Current Price', f\"${{price:.2f}}\"],\n",
    "        ['YTD Performance', f\"{{ytd_perf:.2f}}%\"],\n",
    "        ['Risk Level', risk_level]\n",
    "    ]\n",
    "    \n",
    "    summary_table = Table(summary_data)\n",
    "    summary_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "    ]))\n",
    "    \n",
    "    story.append(summary_table)\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Stock Data Section\n",
    "    story.append(Paragraph(\"Market Data\", styles['Heading2']))\n",
    "    story.append(Paragraph(stock_data.replace('\\\\n', '<br/>'), styles['Normal']))\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Analysis Section\n",
    "    story.append(Paragraph(\"Performance Analysis\", styles['Heading2']))\n",
    "    story.append(Paragraph(analysis_data.replace('\\\\n', '<br/>'), styles['Normal']))\n",
    "    \n",
    "    # Generate timestamp\n",
    "    story.append(Spacer(1, 20))\n",
    "    story.append(Paragraph(f\"Report Generated: {{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}}\", styles['Normal']))\n",
    "    story.append(Paragraph(\"This report is for informational purposes only.\", styles['Normal']))\n",
    "    \n",
    "    doc.build(story)\n",
    "\n",
    "# Custom wrapper to make SagemakerEndpoint work with LangGraph tool binding\n",
    "class SagemakerLLMWrapper:\n",
    "    def __init__(self, sagemaker_llm, tools):\n",
    "        self.sagemaker_llm = sagemaker_llm\n",
    "        self.tools = tools\n",
    "    \n",
    "    def bind_tools(self, tools):\n",
    "        self.tools = tools\n",
    "        return self\n",
    "    \n",
    "    def invoke(self, messages):\n",
    "        # Extract the user message content\n",
    "        user_content = \"\"\n",
    "        for msg in messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                user_content = msg.content\n",
    "                break\n",
    "        \n",
    "        # Check if this is a stock analysis request\n",
    "        if any(keyword in user_content.lower() for keyword in ['analyze', 'stock', 'ticker', 'symbol']):\n",
    "            # Extract stock symbol from user input\n",
    "            stock_match = re.search(r'\\\\b([A-Z]{{2,5}})\\\\b', user_content.upper())\n",
    "            if stock_match:\n",
    "                stock_symbol = stock_match.group(1)\n",
    "                \n",
    "                # Step 1: Gather stock data\n",
    "                print(f\"Step 1: Gathering data for {{stock_symbol}}...\")\n",
    "                stock_data = self.tools[0].invoke({{\"stock_symbol\": stock_symbol}})\n",
    "                \n",
    "                # Step 2: Analyze stock performance\n",
    "                print(f\"Step 2: Analyzing {{stock_symbol}} performance...\")\n",
    "                analysis_result = self.tools[1].invoke({{\"stock_data\": stock_data}})\n",
    "                \n",
    "                # Step 3: Generate stock report\n",
    "                print(f\"Step 3: Generating report for {{stock_symbol}}...\")\n",
    "                report_result = self.tools[2].invoke({{\"stock_data\": stock_data, \"analysis_data\": analysis_result}})\n",
    "                \n",
    "                # Return comprehensive response\n",
    "                full_response = f\"\"\"**COMPREHENSIVE STOCK ANALYSIS REPORT**\n",
    "\n",
    "**Step 1 - Stock Data Gathering:**\n",
    "{{stock_data}}\n",
    "\n",
    "**Step 2 - Performance Analysis:**\n",
    "{{analysis_result}}\n",
    "\n",
    "**Step 3 - Report Generation:**\n",
    "{{report_result}}\n",
    "\n",
    "---\n",
    "**ANALYSIS COMPLETE:** Comprehensive stock analysis has been performed and a detailed PDF report has been generated for documentation purposes.\"\"\"\n",
    "                \n",
    "                return AIMessage(content=full_response)\n",
    "            else:\n",
    "                return AIMessage(content=\"Please provide a valid stock symbol (e.g., AAPL, GOOGL, TSLA) for analysis.\")\n",
    "        \n",
    "        # For other messages, use the SageMaker model normally\n",
    "        system_msg = \"\"\"You are a professional stock analyst. Provide helpful responses about stock analysis, market trends, and financial metrics for informational purposes only.\"\"\"\n",
    "        \n",
    "        full_prompt = f\"{{system_msg}}\\\\n\\\\nUser: {{user_content}}\"\n",
    "        \n",
    "        # Get response from SageMaker endpoint\n",
    "        response = self.sagemaker_llm.invoke(full_prompt)\n",
    "        \n",
    "        # Return a proper LangChain AIMessage\n",
    "        return AIMessage(content=response)\n",
    "\n",
    "# Define the agent using SageMaker endpoint\n",
    "def create_agent():\n",
    "    \"\"\"Create and configure the LangGraph stock analysis agent with SageMaker endpoint\"\"\"\n",
    "    \n",
    "    # Your SageMaker endpoint configuration\n",
    "    endpoint_name = \"{endpoint_name}\"\n",
    "    \n",
    "    class ContentHandler(LLMContentHandler):\n",
    "        content_type = \"application/json\"\n",
    "        accepts = \"application/json\"\n",
    "\n",
    "        def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "            # GPT-OSS harmony format payload structure\n",
    "            payload = {{\n",
    "                \"model\": \"/opt/ml/model\",\n",
    "                \"input\": [\n",
    "                    {{\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a professional stock analyst. Analyze stocks and provide detailed information for educational purposes only, without investment recommendations.\"\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }}\n",
    "                ],\n",
    "                \"max_output_tokens\": model_kwargs.get(\"max_new_tokens\", 2048),\n",
    "                \"stream\": \"false\",\n",
    "                \"temperature\": model_kwargs.get(\"temperature\", 0.1),\n",
    "                \"top_p\": model_kwargs.get(\"top_p\", 1)\n",
    "            }}\n",
    "            input_str = json.dumps(payload)\n",
    "            return input_str.encode(\"utf-8\")\n",
    "\n",
    "        def transform_output(self, output: bytes) -> str:\n",
    "            # Parse harmony format response\n",
    "            decoded_output = output.read().decode(\"utf-8\")\n",
    "            response_json = json.loads(decoded_output)\n",
    "            \n",
    "            if 'output' in response_json and isinstance(response_json['output'], list):\n",
    "                for item in response_json['output']:\n",
    "                    if item.get('type') == 'message' and item.get('role') == 'assistant':\n",
    "                        content = item.get('content', [])\n",
    "                        for content_item in content:\n",
    "                            if content_item.get('type') == 'output_text':\n",
    "                                return content_item.get('text', '')\n",
    "                \n",
    "                # Fallback parsing for different harmony format structures\n",
    "                for item in response_json['output']:\n",
    "                    if item.get('type') != 'reasoning' and 'content' in item and isinstance(item['content'], list):\n",
    "                        for content_item in item['content']:\n",
    "                            if content_item.get('type') == 'output_text':\n",
    "                                return content_item.get('text', '')\n",
    "            \n",
    "            # Final fallback - return raw response\n",
    "            return str(response_json)\n",
    "    \n",
    "    # Initialize SageMaker LLM with harmony format\n",
    "    content_handler = ContentHandler()\n",
    "    sagemaker_llm = SagemakerEndpoint(\n",
    "        endpoint_name=endpoint_name,\n",
    "        region_name=\"us-east-2\",\n",
    "        model_kwargs={{\n",
    "            \"max_new_tokens\": 2048, \n",
    "            \"do_sample\": True, \n",
    "            \"temperature\": 0.1,  # Lower temperature for consistent analysis\n",
    "            \"top_p\": 1\n",
    "        }},\n",
    "        content_handler=content_handler\n",
    "    )\n",
    "    \n",
    "    # Create tools (3 tools: data gathering, analysis, report generation)\n",
    "    tools = [gather_stock_data, analyze_stock_performance, generate_stock_report]\n",
    "    \n",
    "    # Wrap SageMaker LLM to work with LangGraph\n",
    "    llm_with_tools = SagemakerLLMWrapper(sagemaker_llm, tools)\n",
    "    \n",
    "    # System message for stock analysis\n",
    "    system_message = \"\"\"You are a professional stock analyst with expertise in technical analysis, fundamental analysis, and report generation. \n",
    "\n",
    "Your role is to:\n",
    "1. Gather comprehensive stock data from multiple sources including price history, financial metrics, and market data\n",
    "2. Analyze stock performance using both technical and fundamental analysis techniques\n",
    "3. Generate professional stock reports for documentation and educational purposes\n",
    "\n",
    "Provide informational analysis only, without investment recommendations or advice.\"\"\"\n",
    "    \n",
    "    # Define the chatbot node\n",
    "    def chatbot(state: MessagesState):\n",
    "        # Add system message if not already present\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_message)] + messages\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        return {{\"messages\": [response]}}\n",
    "    \n",
    "    # Create the graph\n",
    "    graph_builder = StateGraph(MessagesState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "    graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    # Add edges\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "    \n",
    "    # Set entry point\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent()\n",
    "\n",
    "def langgraph_stock_sagemaker(payload):\n",
    "    \"\"\"\n",
    "    Invoke the stock analysis agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    \n",
    "    # Create the input in the format expected by LangGraph\n",
    "    response = agent.invoke({{\"messages\": [HumanMessage(content=user_input)]}})\n",
    "    \n",
    "    # Extract the final message content\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    response = langgraph_stock_sagemaker(json.loads(args.payload))\n",
    "    print(response)\n",
    "'''\n",
    "    \n",
    "    # Write the file\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(code_content)\n",
    "    \n",
    "    print(f\"Created {filename} with endpoint: {endpoint_name}\")\n",
    "    return filename\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual SageMaker endpoint name\n",
    "    create_local_stock_agent_file(sagemaker_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68499675-db8d-47c6-8c0c-5d66dcb06229",
   "metadata": {},
   "source": [
    "#### Invoking local agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1226d59e6b56c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:52:06.461281Z",
     "start_time": "2025-06-29T21:52:06.456854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Gathering data for AMZN...\n",
      "Step 2: Analyzing AMZN performance...\n",
      "Step 3: Generating report for AMZN...\n",
      "**COMPREHENSIVE STOCK ANALYSIS REPORT**\n",
      "\n",
      "**Step 1 - Stock Data Gathering:**\n",
      "STOCK DATA GATHERING REPORT:\n",
      "================================\n",
      "Stock Symbol: AMZN\n",
      "Company Name: Amazon.com, Inc.\n",
      "Sector: Consumer Cyclical\n",
      "Industry: Internet Retail\n",
      "\n",
      "CURRENT MARKET DATA:\n",
      "- Current Price: $234.69\n",
      "- Market Cap: $2,539,781,357,568 \n",
      "- 52-Week High: $258.60\n",
      "- 52-Week Low: $161.38\n",
      "- YTD Return: 15.83%\n",
      "- Volatility (Annualized): 34.81%\n",
      "\n",
      "FINANCIAL METRICS:\n",
      "- P/E Ratio: 33.10155\n",
      "- Forward P/E: 38.160976\n",
      "- Price-to-Book: 6.785497\n",
      "- Dividend Yield: 0.00%\n",
      "- Revenue (TTM): $691,330,023,424\n",
      "- Profit Margin: 11.06%\n",
      "\n",
      "TRADING METRICS:\n",
      "- Average Volume: 45,392,107\n",
      "- Beta: 1.368\n",
      "- EPS (TTM): $7.09\n",
      "- Book Value: $34.587\n",
      "\n",
      "RECENT NEWS HEADLINES:\n",
      "- AMZN reports quarterly earnings with mixed results\n",
      "- Analysts upgrade AMZN price target amid strong fundamentals\n",
      "- AMZN announces new strategic partnership\n",
      "- Market volatility affects AMZN trading volume\n",
      "\n",
      "DATA COLLECTION TIMESTAMP: 2025-11-17 04:48:55\n",
      "\n",
      "\n",
      "**Step 2 - Performance Analysis:**\n",
      "STOCK PERFORMANCE ANALYSIS:\n",
      "===============================\n",
      "Stock: AMZN | Current Price: $234.69\n",
      "\n",
      "\n",
      "TECHNICAL ANALYSIS:\n",
      "- Price Trend: MODERATE UPTREND\n",
      "- YTD Performance: 15.83%\n",
      "- Volatility Level: 34.81% (MEDIUM RISK)\n",
      "- Volatility Assessment: MEDIUM Risk\n",
      "\n",
      "FUNDAMENTAL ANALYSIS:\n",
      "- P/E Ratio: 33.10155\n",
      "- Profit Margin: 11.06%\n",
      "- Dividend Yield: 0.00%\n",
      "- Beta: 1.368\n",
      "\n",
      "KEY OBSERVATIONS:\n",
      "• P/E ratio suggests potential overvaluation\n",
      "• Good profit margins\n",
      "• Low or no dividend yield\n",
      "\n",
      "\n",
      "ANALYST SUMMARY:\n",
      "Based on technical and fundamental analysis, AMZN shows moderate uptrend with medium volatility profile. \n",
      "The analysis reflects current market conditions and financial performance metrics for informational purposes.\n",
      "\n",
      "DISCLAIMER: This analysis is for informational purposes only and does not constitute investment advice.\n",
      "\n",
      "\n",
      "**Step 3 - Report Generation:**\n",
      "STOCK REPORT GENERATION:\n",
      "===============================\n",
      "Stock: AMZN (Amazon.com, Inc.)\n",
      "Sector: Consumer Cyclical\n",
      "Current Price: $234.69\n",
      "\n",
      "REPORT SUMMARY:\n",
      "- Technical Analysis: 15.83% YTD performance\n",
      "- Risk Assessment: MEDIUM volatility risk\n",
      "- Report Type: Comprehensive stock analysis for informational purposes\n",
      "- Generated: 2025-11-17 04:48:55\n",
      "\n",
      "PDF report generated: AMZN_Stock_Report_20251117_044855.pdf\n",
      "\n",
      "REPORT CONTENTS:\n",
      "• Executive Summary with key metrics\n",
      "• Detailed market data and financial metrics\n",
      "• Technical and fundamental analysis\n",
      "• Risk assessment and observations\n",
      "• Professional formatting for documentation\n",
      "\n",
      "DISCLAIMER: This report is for informational and educational purposes only. \n",
      "It does not constitute investment advice or recommendations.\n",
      "\n",
      "\n",
      "---\n",
      "**ANALYSIS COMPLETE:** Comprehensive stock analysis has been performed and a detailed PDF report has been generated for documentation purposes.\n"
     ]
    }
   ],
   "source": [
    "!python langgraph_stock_local.py '{\"prompt\": \"Analyze AMZN stock for investment\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39e82a-7eda-4a65-a75d-271f9b9f2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agentcore_deployment_file(endpoint_name, bucket_name, filename=\"langgraph_stock_sagemaker_gpt_oss.py\"):\n",
    "    \"\"\"\n",
    "    Create an AgentCore deployment file with the specified SageMaker endpoint name\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name: SageMaker endpoint name to use\n",
    "        bucket_name: S3 bucket name to use\n",
    "        filename: Output filename (default: langgraph_stock_sagemaker_gpt_oss.py)\n",
    "    \"\"\"\n",
    "    \n",
    "    code_content = f'''from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_aws.llms import SagemakerEndpoint\n",
    "from langchain_aws.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "import argparse\n",
    "import json\n",
    "import re\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib import colors\n",
    "import boto3\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "S3_BUCKET_NAME = \"{bucket_name}\"\n",
    "\n",
    "# Create stock analysis tools\n",
    "@tool\n",
    "def gather_stock_data(stock_symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Gather comprehensive stock data from various sources including price history, \n",
    "    financial metrics, news, and market data.\n",
    "    \n",
    "    Args:\n",
    "        stock_symbol: Stock ticker symbol (e.g., 'AAPL', 'GOOGL', 'TSLA')\n",
    "    \n",
    "    Returns:\n",
    "        Comprehensive stock data including current price, historical performance, \n",
    "        financial metrics, and recent news\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the stock symbol\n",
    "        symbol = stock_symbol.upper().strip()\n",
    "        \n",
    "        # Get stock data using yfinance\n",
    "        stock = yf.Ticker(symbol)\n",
    "        \n",
    "        # Get basic info\n",
    "        info = stock.info\n",
    "        \n",
    "        # Get historical data (1 year)\n",
    "        hist = stock.history(period=\"1y\")\n",
    "        current_price = hist['Close'].iloc[-1] if not hist.empty else 0\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        if len(hist) > 0:\n",
    "            year_high = hist['High'].max()\n",
    "            year_low = hist['Low'].min()\n",
    "            year_start_price = hist['Close'].iloc[0]\n",
    "            ytd_return = ((current_price - year_start_price) / year_start_price) * 100\n",
    "            \n",
    "            # Calculate volatility (standard deviation of daily returns)\n",
    "            daily_returns = hist['Close'].pct_change().dropna()\n",
    "            volatility = daily_returns.std() * (252 ** 0.5) * 100  # Annualized volatility\n",
    "        else:\n",
    "            year_high = year_low = ytd_return = volatility = 0\n",
    "            \n",
    "        # Get recent news (simulated - in production you'd use a real news API)\n",
    "        recent_news = [\n",
    "            f\"{{symbol}} reports quarterly earnings with mixed results\",\n",
    "            f\"Analysts upgrade {{symbol}} price target amid strong fundamentals\",\n",
    "            f\"{{symbol}} announces new strategic partnership\",\n",
    "            f\"Market volatility affects {{symbol}} trading volume\"\n",
    "        ]\n",
    "        \n",
    "        # Format the comprehensive data\n",
    "        stock_data = f\"\"\"STOCK DATA GATHERING REPORT:\n",
    "================================\n",
    "Stock Symbol: {{symbol}}\n",
    "Company Name: {{info.get('longName', 'N/A')}}\n",
    "Sector: {{info.get('sector', 'N/A')}}\n",
    "Industry: {{info.get('industry', 'N/A')}}\n",
    "\n",
    "CURRENT MARKET DATA:\n",
    "- Current Price: ${{current_price:.2f}}\n",
    "- Market Cap: ${{info.get('marketCap', 0):,}} \n",
    "- 52-Week High: ${{year_high:.2f}}\n",
    "- 52-Week Low: ${{year_low:.2f}}\n",
    "- YTD Return: {{ytd_return:.2f}}%\n",
    "- Volatility (Annualized): {{volatility:.2f}}%\n",
    "\n",
    "FINANCIAL METRICS:\n",
    "- P/E Ratio: {{info.get('trailingPE', 'N/A')}}\n",
    "- Forward P/E: {{info.get('forwardPE', 'N/A')}}\n",
    "- Price-to-Book: {{info.get('priceToBook', 'N/A')}}\n",
    "- Dividend Yield: {{info.get('dividendYield', 0) * 100 if info.get('dividendYield') else 0:.2f}}%\n",
    "- Revenue (TTM): ${{info.get('totalRevenue', 0):,}}\n",
    "- Profit Margin: {{info.get('profitMargins', 0) * 100 if info.get('profitMargins') else 0:.2f}}%\n",
    "\n",
    "TRADING METRICS:\n",
    "- Average Volume: {{info.get('averageVolume', 0):,}}\n",
    "- Beta: {{info.get('beta', 'N/A')}}\n",
    "- EPS (TTM): ${{info.get('trailingEps', 'N/A')}}\n",
    "- Book Value: ${{info.get('bookValue', 'N/A')}}\n",
    "\n",
    "RECENT NEWS HEADLINES:\n",
    "{{chr(10).join(f\"- {{news}}\" for news in recent_news)}}\n",
    "\n",
    "DATA COLLECTION TIMESTAMP: {{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}}\n",
    "\"\"\"\n",
    "        \n",
    "        return stock_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"\"\"STOCK DATA GATHERING ERROR:\n",
    "================================\n",
    "Stock Symbol: {{stock_symbol}}\n",
    "Error: Unable to gather comprehensive stock data\n",
    "Details: {{str(e)}}\n",
    "\n",
    "Please verify the stock symbol is correct and try again.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def analyze_stock_performance(stock_data: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze stock performance based on gathered data, providing technical analysis,\n",
    "    fundamental analysis, and risk assessment WITHOUT investment recommendations.\n",
    "    \n",
    "    Args:\n",
    "        stock_data: Raw stock data from the data gathering agent\n",
    "    \n",
    "    Returns:\n",
    "        Comprehensive stock analysis including technical indicators, fundamental analysis,\n",
    "        and risk assessment for informational purposes only\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extract key metrics from stock data\n",
    "    symbol_match = re.search(r'Stock Symbol: ([A-Z]+)', stock_data)\n",
    "    price_match = re.search(r'Current Price: \\\\$([\\\\d.]+)', stock_data)\n",
    "    pe_match = re.search(r'P/E Ratio: ([\\\\d.]+)', stock_data)\n",
    "    ytd_match = re.search(r'YTD Return: ([\\\\d.-]+)%', stock_data)\n",
    "    volatility_match = re.search(r'Volatility \\\\(Annualized\\\\): ([\\\\d.]+)%', stock_data)\n",
    "    dividend_match = re.search(r'Dividend Yield: ([\\\\d.]+)%', stock_data)\n",
    "    beta_match = re.search(r'Beta: ([\\\\d.]+)', stock_data)\n",
    "    profit_margin_match = re.search(r'Profit Margin: ([\\\\d.]+)%', stock_data)\n",
    "    \n",
    "    symbol = symbol_match.group(1) if symbol_match else 'UNKNOWN'\n",
    "    current_price = float(price_match.group(1)) if price_match else 0\n",
    "    pe_ratio = float(pe_match.group(1)) if pe_match and pe_match.group(1) != 'N/A' else None\n",
    "    ytd_return = float(ytd_match.group(1)) if ytd_match else 0\n",
    "    volatility = float(volatility_match.group(1)) if volatility_match else 0\n",
    "    dividend_yield = float(dividend_match.group(1)) if dividend_match else 0\n",
    "    beta = float(beta_match.group(1)) if beta_match and beta_match.group(1) != 'N/A' else None\n",
    "    profit_margin = float(profit_margin_match.group(1)) if profit_margin_match else 0\n",
    "    \n",
    "    # Technical Analysis (descriptive only)\n",
    "    if ytd_return > 20:\n",
    "        price_trend = \"STRONG UPTREND\"\n",
    "    elif ytd_return > 10:\n",
    "        price_trend = \"MODERATE UPTREND\"\n",
    "    elif ytd_return > 0:\n",
    "        price_trend = \"SLIGHT UPTREND\"\n",
    "    elif ytd_return > -10:\n",
    "        price_trend = \"SLIGHT DOWNTREND\"\n",
    "    else:\n",
    "        price_trend = \"STRONG DOWNTREND\"\n",
    "    \n",
    "    # Fundamental Analysis (descriptive only)\n",
    "    fundamental_factors = []\n",
    "    \n",
    "    if pe_ratio:\n",
    "        if pe_ratio < 15:\n",
    "            fundamental_factors.append(\"P/E ratio suggests potential undervaluation\")\n",
    "        elif pe_ratio < 25:\n",
    "            fundamental_factors.append(\"P/E ratio within reasonable range\")\n",
    "        else:\n",
    "            fundamental_factors.append(\"P/E ratio suggests potential overvaluation\")\n",
    "    \n",
    "    if profit_margin > 20:\n",
    "        fundamental_factors.append(\"Excellent profit margins\")\n",
    "    elif profit_margin > 10:\n",
    "        fundamental_factors.append(\"Good profit margins\")\n",
    "    else:\n",
    "        fundamental_factors.append(\"Low profit margins\")\n",
    "    \n",
    "    if dividend_yield > 3:\n",
    "        fundamental_factors.append(\"High dividend yield\")\n",
    "    elif dividend_yield > 1:\n",
    "        fundamental_factors.append(\"Moderate dividend yield\")\n",
    "    else:\n",
    "        fundamental_factors.append(\"Low or no dividend yield\")\n",
    "    \n",
    "    \n",
    "    beta_description = \"\"\n",
    "    if beta and beta > 1.5:\n",
    "        beta_description = \"High beta indicates sensitivity to market movements\"\n",
    "    elif beta and beta < 0.5:\n",
    "        beta_description = \"Low beta indicates stability relative to market\"\n",
    "    else:\n",
    "        beta_description = \"Beta indicates moderate market correlation\"\n",
    "    \n",
    "    analysis_report = f\"\"\"STOCK PERFORMANCE ANALYSIS:\n",
    "===============================\n",
    "Stock: {{symbol}} | Current Price: ${{current_price:.2f}}\n",
    "\n",
    "TECHNICAL ANALYSIS:\n",
    "- Price Trend: {{price_trend}}\n",
    "- YTD Performance: {{ytd_return:.2f}}%\n",
    "\n",
    "\n",
    "FUNDAMENTAL ANALYSIS:\n",
    "- P/E Ratio: {{pe_ratio if pe_ratio else 'N/A'}}\n",
    "- Profit Margin: {{profit_margin:.2f}}%\n",
    "- Dividend Yield: {{dividend_yield:.2f}}%\n",
    "- Beta: {{beta if beta else 'N/A'}}\n",
    "\n",
    "KEY OBSERVATIONS:\n",
    "{{chr(10).join(f\"• {{factor}}\" for factor in fundamental_factors)}}\n",
    "\n",
    "\n",
    "\n",
    "ANALYST SUMMARY:\n",
    "Based on technical and fundamental analysis, {{symbol}} shows {{price_trend.lower()}} with {{risk_level.lower()}} volatility profile. \n",
    "The analysis reflects current market conditions and financial performance metrics for informational purposes.\n",
    "\n",
    "DISCLAIMER: This analysis is for informational purposes only and does not constitute investment advice.\n",
    "\"\"\"\n",
    "    \n",
    "    return analysis_report\n",
    "\n",
    "@tool\n",
    "def generate_stock_report(stock_data: str, analysis_data: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive stock report based on gathered data and analysis.\n",
    "    Creates a professional PDF report and uploads to S3 for documentation purposes.\n",
    "    \n",
    "    Args:\n",
    "        stock_data: Raw stock data from the data gathering agent\n",
    "        analysis_data: Analysis results from the performance analyzer\n",
    "    \n",
    "    Returns:\n",
    "        Report generation summary with PDF creation and S3 upload status\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extract key information for report\n",
    "    symbol_match = re.search(r'Stock Symbol: ([A-Z]+)', stock_data)\n",
    "    price_match = re.search(r'Current Price: \\\\$([\\\\d.]+)', stock_data)\n",
    "    company_match = re.search(r'Company Name: ([^\\\\n]+)', stock_data)\n",
    "    sector_match = re.search(r'Sector: ([^\\\\n]+)', stock_data)\n",
    "    ytd_match = re.search(r'YTD Performance: ([\\\\d.-]+)%', analysis_data)\n",
    "    risk_match = re.search(r'Volatility Risk: ([A-Z]+)', analysis_data)\n",
    "    \n",
    "    symbol = symbol_match.group(1) if symbol_match else 'UNKNOWN'\n",
    "    current_price = float(price_match.group(1)) if price_match else 0\n",
    "    company_name = company_match.group(1).strip() if company_match else 'N/A'\n",
    "    sector = sector_match.group(1).strip() if sector_match else 'N/A'\n",
    "    ytd_performance = float(ytd_match.group(1)) if ytd_match else 0\n",
    "    risk_level = risk_match.group(1) if risk_match else 'MEDIUM'\n",
    "    \n",
    "    # Generate PDF report and upload to S3\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    pdf_filename = f\"{{symbol}}_Stock_Report_{{timestamp}}.pdf\"\n",
    "    \n",
    "    try:\n",
    "        s3_path = create_and_upload_stock_report_pdf(\n",
    "            symbol, company_name, sector, current_price, \n",
    "            ytd_performance, risk_level, stock_data, analysis_data, pdf_filename\n",
    "        )\n",
    "        pdf_status = f\"PDF report uploaded to S3: {{s3_path}}\"\n",
    "    except Exception as e:\n",
    "        pdf_status = f\"PDF generation/upload failed: {{str(e)}}\"\n",
    "    \n",
    "    report_summary = f\"\"\"STOCK REPORT GENERATION:\n",
    "===============================\n",
    "Stock: {{symbol}} ({{company_name}})\n",
    "Sector: {{sector}}\n",
    "Current Price: ${{current_price:.2f}}\n",
    "\n",
    "REPORT SUMMARY:\n",
    "- Technical Analysis: {{ytd_performance:.2f}}% YTD performance\n",
    "- Risk Assessment: {{risk_level}} volatility risk\n",
    "- Report Type: Comprehensive stock analysis for informational purposes\n",
    "- Generated: {{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}}\n",
    "\n",
    "{{pdf_status}}\n",
    "\n",
    "REPORT CONTENTS:\n",
    "• Executive Summary with key metrics\n",
    "• Detailed market data and financial metrics\n",
    "• Technical and fundamental analysis\n",
    "• Risk assessment and observations\n",
    "• Professional formatting for documentation\n",
    "\n",
    "DISCLAIMER: This report is for informational and educational purposes only. \n",
    "It does not constitute investment advice or recommendations.\n",
    "\"\"\"\n",
    "    \n",
    "    return report_summary\n",
    "\n",
    "def create_and_upload_stock_report_pdf(symbol, company_name, sector, price, ytd_perf, risk_level, stock_data, analysis_data, filename):\n",
    "    \"\"\"Create a professional PDF stock report and upload to S3\"\"\"\n",
    "    \n",
    "    # Create PDF in temporary file\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
    "        doc = SimpleDocTemplate(tmp_file.name, pagesize=letter)\n",
    "        styles = getSampleStyleSheet()\n",
    "        story = []\n",
    "        \n",
    "        # Title\n",
    "        title_style = ParagraphStyle(\n",
    "            'CustomTitle',\n",
    "            parent=styles['Heading1'],\n",
    "            fontSize=18,\n",
    "            spaceAfter=30,\n",
    "            textColor=colors.darkblue\n",
    "        )\n",
    "        story.append(Paragraph(f\"Stock Analysis Report: {{symbol}}\", title_style))\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # Executive Summary\n",
    "        story.append(Paragraph(\"Executive Summary\", styles['Heading2']))\n",
    "        summary_data = [\n",
    "            ['Metric', 'Value'],\n",
    "            ['Stock Symbol', symbol],\n",
    "            ['Company Name', company_name],\n",
    "            ['Sector', sector],\n",
    "            ['Current Price', f\"${{price:.2f}}\"],\n",
    "            ['YTD Performance', f\"{{ytd_perf:.2f}}%\"],\n",
    "            ['Risk Level', risk_level]\n",
    "        ]\n",
    "        \n",
    "        summary_table = Table(summary_data)\n",
    "        summary_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "            ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "        ]))\n",
    "        \n",
    "        story.append(summary_table)\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Stock Data Section\n",
    "        story.append(Paragraph(\"Market Data\", styles['Heading2']))\n",
    "        story.append(Paragraph(stock_data.replace('\\\\n', '<br/>'), styles['Normal']))\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Analysis Section\n",
    "        story.append(Paragraph(\"Performance Analysis\", styles['Heading2']))\n",
    "        story.append(Paragraph(analysis_data.replace('\\\\n', '<br/>'), styles['Normal']))\n",
    "        \n",
    "        # Generate timestamp\n",
    "        story.append(Spacer(1, 20))\n",
    "        story.append(Paragraph(f\"Report Generated: {{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}}\", styles['Normal']))\n",
    "        story.append(Paragraph(\"This report is for informational purposes only.\", styles['Normal']))\n",
    "        \n",
    "        doc.build(story)\n",
    "        \n",
    "        # Upload to S3\n",
    "        s3_key = datetime.now().strftime('%Y/%m/%d') + \"/\" + filename\n",
    "        \n",
    "        try:\n",
    "            s3_client.upload_file(tmp_file.name, S3_BUCKET_NAME, s3_key)\n",
    "            s3_path = f\"s3://{{S3_BUCKET_NAME}}/{{s3_key}}\"\n",
    "            \n",
    "            # Clean up temporary file\n",
    "            os.unlink(tmp_file.name)\n",
    "            \n",
    "            return s3_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Clean up temporary file on error\n",
    "            os.unlink(tmp_file.name)\n",
    "            raise e\n",
    "\n",
    "# Custom wrapper to make SagemakerEndpoint work with LangGraph tool binding\n",
    "class SagemakerLLMWrapper:\n",
    "    def __init__(self, sagemaker_llm, tools):\n",
    "        self.sagemaker_llm = sagemaker_llm\n",
    "        self.tools = tools\n",
    "        self.tool_map = {{tool.name: tool for tool in tools}}\n",
    "    \n",
    "    def bind_tools(self, tools):\n",
    "        # Return self since we're already configured with tools\n",
    "        return self\n",
    "    \n",
    "    def invoke(self, messages):\n",
    "        # Extract the user message content\n",
    "        user_content = \"\"\n",
    "        for msg in messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                user_content = msg.content\n",
    "                break\n",
    "        \n",
    "        # Check if this is a stock analysis request\n",
    "        if any(keyword in user_content.lower() for keyword in ['analyze', 'stock', 'ticker', 'symbol']):\n",
    "            # Extract stock symbol from user input\n",
    "            stock_match = re.search(r'\\\\b([A-Z]{{2,5}})\\\\b', user_content.upper())\n",
    "            if stock_match:\n",
    "                stock_symbol = stock_match.group(1)\n",
    "                \n",
    "                # Step 1: Gather stock data\n",
    "                print(f\"Step 1: Gathering data for {{stock_symbol}}...\")\n",
    "                stock_data = self.tools[0].invoke({{\"stock_symbol\": stock_symbol}})\n",
    "                \n",
    "                # Step 2: Analyze stock performance\n",
    "                print(f\"Step 2: Analyzing {{stock_symbol}} performance...\")\n",
    "                analysis_result = self.tools[1].invoke({{\"stock_data\": stock_data}})\n",
    "                \n",
    "                # Step 3: Generate stock report\n",
    "                print(f\"Step 3: Generating report for {{stock_symbol}}...\")\n",
    "                report_result = self.tools[2].invoke({{\"stock_data\": stock_data, \"analysis_data\": analysis_result}})\n",
    "                \n",
    "                # Return comprehensive response\n",
    "                full_response = f\"\"\"**COMPREHENSIVE STOCK ANALYSIS REPORT**\n",
    "\n",
    "**Step 1 - Stock Data Gathering:**\n",
    "{{stock_data}}\n",
    "\n",
    "**Step 2 - Performance Analysis:**\n",
    "{{analysis_result}}\n",
    "\n",
    "**Step 3 - Report Generation:**\n",
    "{{report_result}}\n",
    "\n",
    "---\n",
    "**ANALYSIS COMPLETE:** Comprehensive stock analysis has been performed and a detailed PDF report has been generated and uploaded to S3 for documentation purposes.\"\"\"\n",
    "                \n",
    "                return AIMessage(content=full_response)\n",
    "            else:\n",
    "                return AIMessage(content=\"Please provide a valid stock symbol (e.g., AAPL, GOOGL, TSLA) for analysis.\")\n",
    "        \n",
    "        # For other messages, use the SageMaker model normally\n",
    "        system_msg = \"\"\"You are a professional stock analyst. Provide helpful responses about stock analysis, market trends, and financial metrics for informational purposes only.\"\"\"\n",
    "        \n",
    "        full_prompt = f\"{{system_msg}}\\\\n\\\\nUser: {{user_content}}\"\n",
    "        \n",
    "        # Get response from SageMaker endpoint\n",
    "        response = self.sagemaker_llm.invoke(full_prompt)\n",
    "        \n",
    "        # Return a proper LangChain AIMessage\n",
    "        return AIMessage(content=response)\n",
    "\n",
    "# Define the agent using SageMaker endpoint\n",
    "def create_agent():\n",
    "    \"\"\"Create and configure the LangGraph stock analysis agent with SageMaker endpoint\"\"\"\n",
    "    \n",
    "    # Your SageMaker endpoint configuration\n",
    "    endpoint_name = \"{endpoint_name}\"\n",
    "    \n",
    "    class ContentHandler(LLMContentHandler):\n",
    "        content_type = \"application/json\"\n",
    "        accepts = \"application/json\"\n",
    "\n",
    "        def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "            # GPT-OSS harmony format payload structure\n",
    "            payload = {{\n",
    "                \"model\": \"/opt/ml/model\",\n",
    "                \"input\": [\n",
    "                    {{\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a professional stock analyst. Analyze stocks and provide detailed information for educational purposes only, without investment recommendations.\"\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }}\n",
    "                ],\n",
    "                \"max_output_tokens\": model_kwargs.get(\"max_new_tokens\", 2048),\n",
    "                \"stream\": \"false\",\n",
    "                \"temperature\": model_kwargs.get(\"temperature\", 0.1),\n",
    "                \"top_p\": model_kwargs.get(\"top_p\", 1)\n",
    "            }}\n",
    "            input_str = json.dumps(payload)\n",
    "            return input_str.encode(\"utf-8\")\n",
    "\n",
    "        def transform_output(self, output: bytes) -> str:\n",
    "            # Parse harmony format response\n",
    "            decoded_output = output.read().decode(\"utf-8\")\n",
    "            response_json = json.loads(decoded_output)\n",
    "            \n",
    "            if 'output' in response_json and isinstance(response_json['output'], list):\n",
    "                for item in response_json['output']:\n",
    "                    if item.get('type') == 'message' and item.get('role') == 'assistant':\n",
    "                        content = item.get('content', [])\n",
    "                        for content_item in content:\n",
    "                            if content_item.get('type') == 'output_text':\n",
    "                                return content_item.get('text', '')\n",
    "                \n",
    "                # Fallback parsing for different harmony format structures\n",
    "                for item in response_json['output']:\n",
    "                    if item.get('type') != 'reasoning' and 'content' in item and isinstance(item['content'], list):\n",
    "                        for content_item in item['content']:\n",
    "                            if content_item.get('type') == 'output_text' and 'text' in content_item:\n",
    "                                return content_item['text']\n",
    "                \n",
    "                for item in response_json['output']:\n",
    "                    if 'content' in item and isinstance(item['content'], list):\n",
    "                        for content_item in item['content']:\n",
    "                            if 'text' in content_item:\n",
    "                                return content_item['text']\n",
    "            \n",
    "            return str(response_json)\n",
    "\n",
    "    # Initialize SageMaker LLM with harmony format\n",
    "    content_handler = ContentHandler()\n",
    "    sagemaker_llm = SagemakerEndpoint(\n",
    "        endpoint_name=endpoint_name,\n",
    "        region_name=\"us-west-2\",\n",
    "        model_kwargs={{\n",
    "            \"max_new_tokens\": 2048, \n",
    "            \"do_sample\": True, \n",
    "            \"temperature\": 0.1,  # Lower temperature for consistent analysis\n",
    "            \"top_p\": 1\n",
    "        }},\n",
    "        content_handler=content_handler\n",
    "    )\n",
    "    \n",
    "    # Create tools (3 tools: data gathering, analysis, report generation)\n",
    "    tools = [gather_stock_data, analyze_stock_performance, generate_stock_report]\n",
    "    \n",
    "    # Wrap SageMaker LLM to work with LangGraph\n",
    "    llm_with_tools = SagemakerLLMWrapper(sagemaker_llm, tools)\n",
    "    \n",
    "    # System message for stock analysis\n",
    "    system_message = \"\"\"You are a professional stock analyst with expertise in technical analysis, fundamental analysis, and report generation. \n",
    "\n",
    "Your role is to:\n",
    "1. Gather comprehensive stock data from multiple sources including price history, financial metrics, and market data\n",
    "2. Analyze stock performance using both technical and fundamental analysis techniques\n",
    "3. Generate professional stock reports for documentation and educational purposes\n",
    "\n",
    "Provide informational analysis only, without investment recommendations or advice.\"\"\"\n",
    "    \n",
    "    # Define the chatbot node\n",
    "    def chatbot(state: MessagesState):\n",
    "        # Add system message if not already present\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_message)] + messages\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        return {{\"messages\": [response]}}\n",
    "    \n",
    "    # Create the graph\n",
    "    graph_builder = StateGraph(MessagesState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "    graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    # Add edges\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "    \n",
    "    # Set entry point\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent()\n",
    "\n",
    "@app.entrypoint\n",
    "def langgraph_stock_sagemaker(payload):\n",
    "    \"\"\"\n",
    "    Invoke the stock analysis agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    \n",
    "    # Create the input in the format expected by LangGraph\n",
    "    response = agent.invoke({{\"messages\": [HumanMessage(content=user_input)]}})\n",
    "    \n",
    "    # Extract the final message content\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "'''\n",
    "    \n",
    "    # Write the file\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(code_content)\n",
    "    \n",
    "    print(f\"Created {filename} with endpoint: {endpoint_name} and bucket: {bucket_name}\")\n",
    "    return filename\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual values\n",
    "    sagemaker_endpoint_name = \"gpt-oss-120b-2025-11-05-01-53-27-686\"\n",
    "    bucket_name = \"gpt-oss-agentic-demo\"\n",
    "    create_agentcore_deployment_file(sagemaker_endpoint_name, bucket_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## Preparing your agent for deployment on AgentCore Runtime\n",
    "\n",
    "Let's now deploy our agents to AgentCore Runtime. To do so we need to:\n",
    "* Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "* Initialize the App in our code with `app = BedrockAgentCoreApp()`\n",
    "* Decorate the invocation function with the `@app.entrypoint` decorator\n",
    "* Let AgentCoreRuntime control the running of the agent with `app.run()`\n",
    "\n",
    "### LangGraph with Amazon SageMaker GLM 4.5 model\n",
    "Let's start with our LangGraph using Amazon SageMaker AI GLM 4.5 model. Other examples with different \n",
    "frameworks and models are available in the parent directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "## What happens behind the scenes?\n",
    "\n",
    "When you use `BedrockAgentCoreApp`, it automatically:\n",
    "\n",
    "* Creates an HTTP server that listens on the port 8080\n",
    "* Implements the required `/invocations` endpoint for processing the agent's requirements\n",
    "* Implements the `/ping` endpoint for health checks (very important for asynchronous agents)\n",
    "* Handles proper content types and response formats\n",
    "* Manages error handling according to the AWS standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "## Deploying the agent to AgentCore Runtime\n",
    "\n",
    "The `CreateAgentRuntime` operation supports comprehensive configuration options, letting you specify container images, environment variables and encryption settings. You can also configure protocol settings (HTTP, MCP) and authorization mechanisms to control how your clients communicate with the agent. \n",
    "\n",
    "**Note:** Operations best practice is to package code as container and push to ECR using CI/CD pipelines and IaC\n",
    "\n",
    "In this tutorial can will the Amazon Bedrock AgentCode Python SDK to easily package your artifacts and deploy them to AgentCore runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f050b21-a845-45b2-b4fc-eca56e4b0af3",
   "metadata": {},
   "source": [
    "### Creating IAM Role for Bedrock AgentCore Runtime\n",
    "\n",
    "Before deploying our Stock Analysis agent to Bedrock AgentCore Runtime, we need to create an IAM role with the appropriate permissions. This role will allow AgentCore to:\n",
    "\n",
    "• **Invoke your SageMaker endpoint** for GPT-OSS model inference  \n",
    "• **Manage ECR repositories** for storing container images  \n",
    "• **Write CloudWatch logs** for monitoring and debugging  \n",
    "• **Access Bedrock AgentCore workload services** for runtime operations  \n",
    "• **Send telemetry data** to X-Ray and CloudWatch for observability  \n",
    "\n",
    "The function below creates a comprehensive IAM role with five custom policies plus the AWS managed \n",
    "AmazonBedrockFullAccess policy. Each policy is scoped to only the resources needed for AgentCore operations, \n",
    "following the principle of least privilege.\n",
    "\n",
    "**Key Features**:  \n",
    "\n",
    "• **Automatic policy creation** with timestamped names to avoid conflicts  \n",
    "• **Error handling** for existing roles and policies  \n",
    "• **Resource-specific permissions** (scoped to your SageMaker endpoint and ECR repositories)  \n",
    "• **Ready-to-use role ARN** for AgentCore configuration  \n",
    "\n",
    "This approach ensures your agent has exactly the permissions it needs to run securely in the AgentCore Runtime \n",
    "environment while maintaining access to your specific SageMaker model endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee606a-e9aa-4156-b5e2-7aa72b477712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def add_s3_inline_policy_to_role(role_name, s3_bucket_name, region=\"us-west-2\"):\n",
    "    \"\"\"\n",
    "    Add S3 permissions as an inline policy to an existing role\n",
    "    \n",
    "    Args:\n",
    "        role_name: Existing IAM role name\n",
    "        s3_bucket_name: S3 bucket name for PDF uploads\n",
    "        region: AWS region\n",
    "    \"\"\"\n",
    "    \n",
    "    iam_client = boto3.client('iam', region_name=region)\n",
    "    \n",
    "    print(f\"Adding S3 inline policy to role: {role_name}\")\n",
    "    print(f\"S3 Bucket: {s3_bucket_name}\")\n",
    "    \n",
    "    # S3 policy document\n",
    "    s3_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:PutObject\",\n",
    "                    \"s3:PutObjectAcl\",\n",
    "                    \"s3:GetObject\",\n",
    "                    \"s3:DeleteObject\"\n",
    "                ],\n",
    "                \"Resource\": f\"arn:aws:s3:::{s3_bucket_name}/*\"\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:ListBucket\",\n",
    "                    \"s3:GetBucketLocation\"\n",
    "                ],\n",
    "                \"Resource\": f\"arn:aws:s3:::{s3_bucket_name}\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Add inline policy to role\n",
    "    policy_name = \"S3AccessForStockAnalysis\"\n",
    "    \n",
    "    try:\n",
    "        iam_client.put_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyName=policy_name,\n",
    "            PolicyDocument=json.dumps(s3_policy)\n",
    "        )\n",
    "        print(f\"Successfully added inline S3 policy: {policy_name}\")\n",
    "        print(f\"Role {role_name} now has access to bucket: {s3_bucket_name}\")\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"Error adding inline policy: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return True\n",
    "\n",
    "def list_role_policies(role_name, region=\"us-west-2\"):\n",
    "    \"\"\"List all policies attached to a role\"\"\"\n",
    "    \n",
    "    iam_client = boto3.client('iam', region_name=region)\n",
    "    \n",
    "    print(f\"Policies for role: {role_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # List attached managed policies\n",
    "        attached_policies = iam_client.list_attached_role_policies(RoleName=role_name)\n",
    "        print(f\"Managed Policies ({len(attached_policies['AttachedPolicies'])}):\")\n",
    "        for policy in attached_policies['AttachedPolicies']:\n",
    "            print(f\"  - {policy['PolicyName']}\")\n",
    "        \n",
    "        # List inline policies\n",
    "        inline_policies = iam_client.list_role_policies(RoleName=role_name)\n",
    "        print(f\"\\nInline Policies ({len(inline_policies['PolicyNames'])}):\")\n",
    "        for policy_name in inline_policies['PolicyNames']:\n",
    "            print(f\"  - {policy_name}\")\n",
    "            \n",
    "    except ClientError as e:\n",
    "        print(f\"Error listing policies: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    role_name = \"MyBedrockAgentCoreRole\"\n",
    "    s3_bucket_name = \"surya-495365983931\"\n",
    "    region = \"us-west-2\"\n",
    "    \n",
    "    # First, let's see what policies are currently attached\n",
    "    print(\"Current policies:\")\n",
    "    list_role_policies(role_name, region)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Add S3 permissions as inline policy\n",
    "    add_s3_inline_policy_to_role(role_name, s3_bucket_name, region)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Show updated policies\n",
    "    print(\"Updated policies:\")\n",
    "    list_role_policies(role_name, region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "### Configure AgentCore Runtime deployment\n",
    "\n",
    "First we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "agent_name = \"langgraph_stock_analyzer_agent\"\n",
    "\n",
    "boto_session = Session()\n",
    "region = \"us-west-2\"\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "# Configure the agent (this doesn't require Docker)\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"langgraph_stock_sagemaker_gpt_oss.py\",\n",
    "    auto_create_execution_role=False,\n",
    "    execution_role=role_arn,  # Use custom role\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### Launching agent to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "launch_result = agentcore_runtime.launch(use_codebuild=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17b661-892d-4eaf-8cdf-732d39a7bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_arn = launch_result.agent_arn\n",
    "print(f\"Agent_ARN='{agent_arn}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "### Checking for the AgentCore Runtime Status\n",
    "Now that we've deployed the AgentCore Runtime, let's check for it's deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime\n",
    "\n",
    "Finally, we can invoke our AgentCore Runtime with a payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"Analyze AAPL stock for investment\"})\n",
    "\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "### Parsing and Displaying Stock Analysis Results\n",
    "\n",
    "After invoking our stock analysis agent through AgentCore Runtime, we need to parse and format the response \n",
    "for clear presentation. The agent returns a comprehensive analysis in JSON format containing three distinct \n",
    "phases of the investment research process.\n",
    "\n",
    "This parsing function extracts and displays the stock analysis in a structured format:\n",
    "\n",
    "**Response Processing**:  \n",
    "\n",
    "• **Decodes the byte stream** from AgentCore into readable text  \n",
    "• **Parses the JSON response** containing the complete stock analysis  \n",
    "• **Extracts three main sections** using regex pattern matching:  \n",
    "\n",
    "    • Step 1: Stock data gathering with market metrics and company information  \n",
    "    • Step 2: Performance analysis with technical indicators and fundamental evaluation  \n",
    "    • Step 3: Investment decision with buy/sell/hold recommendations and PDF report generation  \n",
    "\n",
    "**Key Information Extraction**:  \n",
    "\n",
    "• Investment decision (INVEST/HOLD/AVOID) with confidence levels and visual indicators  \n",
    "• Investment rating (STRONG BUY/BUY/HOLD/SELL) showing the quantitative assessment  \n",
    "• Financial metrics including current price, P/E ratio, market cap, and YTD performance  \n",
    "• Risk assessment with volatility analysis and portfolio allocation guidance  \n",
    "• PDF report status with S3 storage location or error details  \n",
    "\n",
    "**Error Handling**:  \n",
    "\n",
    "• Gracefully handles JSON parsing errors  \n",
    "• Falls back to plain text display if structured parsing fails  \n",
    "• Provides debugging information for troubleshooting  \n",
    "• Handles PDF generation failures with detailed error messages  \n",
    "\n",
    "**Additional Features**:\n",
    "\n",
    "• Programmatic data access for integration with other systems  \n",
    "• Structured metrics extraction for quantitative analysis  \n",
    "• Investment summary generation for executive reporting  \n",
    "• S3 path validation for document retrieval  \n",
    "\n",
    "This formatted output makes it easy to review the agent's investment analysis process, access key financial metrics programmatically, and present professional stock research results to portfolio managers and investment committees. \n",
    "\n",
    "The parsing function also provides direct access to generated PDF reports stored in Amazon S3 for comprehensive documentation and audit trails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3da506-0fb0-4ec1-890f-e12de92b894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def parse_bedrock_agentcore_stock_response(invoke_response):\n",
    "    \"\"\"Parse the complete Bedrock AgentCore stock analysis response from byte chunks\"\"\"\n",
    "    \n",
    "    # Combine all byte chunks into one string\n",
    "    response_chunks = invoke_response['response']\n",
    "    complete_response = b''.join(response_chunks).decode('utf-8')\n",
    "    \n",
    "    try:\n",
    "        # Parse the JSON (it's a JSON string containing the analysis)\n",
    "        data = json.loads(complete_response)\n",
    "        \n",
    "        print(\"COMPREHENSIVE STOCK ANALYSIS REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Extract the three main sections using regex\n",
    "        step1_match = re.search(r'\\*\\*Step 1 - Stock Data Gathering:\\*\\*(.*?)\\*\\*Step 2', data, re.DOTALL)\n",
    "        step2_match = re.search(r'\\*\\*Step 2 - Performance Analysis:\\*\\*(.*?)\\*\\*Step 3', data, re.DOTALL)\n",
    "        step3_match = re.search(r'\\*\\*Step 3 - Report Generation:\\*\\*(.*?)---', data, re.DOTALL)\n",
    "        \n",
    "        print(f\"\\nSTEP 1 - STOCK DATA GATHERING:\")\n",
    "        print(\"-\" * 50)\n",
    "        if step1_match:\n",
    "            data_section = step1_match.group(1).strip()\n",
    "            print(data_section)\n",
    "        else:\n",
    "            print(\"Could not extract stock data section\")\n",
    "        \n",
    "        print(f\"\\nSTEP 2 - PERFORMANCE ANALYSIS:\")\n",
    "        print(\"-\" * 50)\n",
    "        if step2_match:\n",
    "            analysis_section = step2_match.group(1).strip()\n",
    "            print(analysis_section)\n",
    "        else:\n",
    "            print(\"Could not extract analysis section\")\n",
    "        \n",
    "        print(f\"\\nSTEP 3 - REPORT GENERATION:\")\n",
    "        print(\"-\" * 50)\n",
    "        if step3_match:\n",
    "            report_section = step3_match.group(1).strip()\n",
    "            print(report_section)\n",
    "            \n",
    "            # Extract key report generation info\n",
    "            ytd_perf_match = re.search(r'Technical Analysis: ([^\\n]+)', report_section)\n",
    "            risk_assess_match = re.search(r'Risk Assessment: ([^\\n]+)', report_section)\n",
    "            report_type_match = re.search(r'Report Type: ([^\\n]+)', report_section)\n",
    "            generated_match = re.search(r'Generated: ([^\\n]+)', report_section)\n",
    "            \n",
    "            print(f\"\\nKEY REPORT METRICS:\")\n",
    "            print(\"-\" * 30)\n",
    "            if ytd_perf_match:\n",
    "                print(f\"YTD Performance: {ytd_perf_match.group(1).strip()}\")\n",
    "            if risk_assess_match:\n",
    "                print(f\"Risk Assessment: {risk_assess_match.group(1).strip()}\")\n",
    "            if report_type_match:\n",
    "                print(f\"Report Type: {report_type_match.group(1).strip()}\")\n",
    "            if generated_match:\n",
    "                print(f\"Generated: {generated_match.group(1).strip()}\")\n",
    "        else:\n",
    "            print(\"Could not extract report section\")\n",
    "        \n",
    "        # Extract stock summary from the data gathering section\n",
    "        symbol_match = re.search(r'Stock Symbol: ([^\\n]+)', data)\n",
    "        company_match = re.search(r'Company Name: ([^\\n]+)', data)\n",
    "        current_price_match = re.search(r'Current Price: \\$([^\\n]+)', data)\n",
    "        ytd_return_match = re.search(r'YTD Return: ([^\\n]+)', data)\n",
    "        market_cap_match = re.search(r'Market Cap: \\$([^\\n]+)', data)\n",
    "        pe_ratio_match = re.search(r'P/E Ratio: ([^\\n]+)', data)\n",
    "        \n",
    "        if symbol_match:\n",
    "            print(f\"\\nSTOCK SUMMARY:\")\n",
    "            print(\"-\" * 25)\n",
    "            if symbol_match:\n",
    "                print(f\"Symbol: {symbol_match.group(1).strip()}\")\n",
    "            if company_match:\n",
    "                print(f\"Company: {company_match.group(1).strip()}\")\n",
    "            if current_price_match:\n",
    "                print(f\"Current Price: ${current_price_match.group(1).strip()}\")\n",
    "            if market_cap_match:\n",
    "                print(f\"Market Cap: ${market_cap_match.group(1).strip()}\")\n",
    "            if pe_ratio_match:\n",
    "                print(f\"P/E Ratio: {pe_ratio_match.group(1).strip()}\")\n",
    "            if ytd_return_match:\n",
    "                print(f\"YTD Return: {ytd_return_match.group(1).strip()}\")\n",
    "        \n",
    "        # Check for PDF upload status\n",
    "        pdf_match = re.search(r'PDF.*?(?:uploaded to S3: (s3://[^\\n]+)|generation/upload failed: ([^\\n]+))', data, re.IGNORECASE)\n",
    "        if pdf_match:\n",
    "            print(f\"\\nPDF REPORT STATUS:\")\n",
    "            print(\"-\" * 25)\n",
    "            if pdf_match.group(1):  # Successful upload\n",
    "                print(f\"PDF uploaded to: {pdf_match.group(1)}\")\n",
    "            elif pdf_match.group(2):  # Failed upload\n",
    "                print(f\"PDF upload failed: {pdf_match.group(2)}\")\n",
    "        \n",
    "        print(f\"\\nSTOCK ANALYSIS COMPLETE\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return {\n",
    "            'stock_data_gathering': step1_match.group(1).strip() if step1_match else None,\n",
    "            'performance_analysis': step2_match.group(1).strip() if step2_match else None,\n",
    "            'report_generation': step3_match.group(1).strip() if step3_match else None,\n",
    "            'stock_symbol': symbol_match.group(1).strip() if symbol_match else None,\n",
    "            'company_name': company_match.group(1).strip() if company_match else None,\n",
    "            'current_price': current_price_match.group(1).strip() if current_price_match else None,\n",
    "            'ytd_performance': ytd_perf_match.group(1).strip() if ytd_perf_match else None,\n",
    "            'risk_assessment': risk_assess_match.group(1).strip() if risk_assess_match else None,\n",
    "            'report_type': report_type_match.group(1).strip() if report_type_match else None,\n",
    "            'generated_time': generated_match.group(1).strip() if generated_match else None,\n",
    "            'ytd_return': ytd_return_match.group(1).strip() if ytd_return_match else None,\n",
    "            'pe_ratio': pe_ratio_match.group(1).strip() if pe_ratio_match else None,\n",
    "            'market_cap': market_cap_match.group(1).strip() if market_cap_match else None,\n",
    "            'pdf_status': pdf_match.group(1) if pdf_match and pdf_match.group(1) else pdf_match.group(2) if pdf_match and pdf_match.group(2) else None,\n",
    "            'raw_response': data\n",
    "        }\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON Error: {e}\")\n",
    "        print(f\"Raw response length: {len(complete_response)}\")\n",
    "        print(f\"First 500 chars: {complete_response[:500]}\")\n",
    "        \n",
    "        # Try to parse as plain text if JSON fails\n",
    "        print(\"\\nATTEMPTING PLAIN TEXT PARSING:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(complete_response)\n",
    "        return {'raw_response': complete_response}\n",
    "\n",
    "# Parse your existing response\n",
    "stock_analysis = parse_bedrock_agentcore_stock_response(invoke_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime with boto3\n",
    "\n",
    "Now that your AgentCore Runtime was created you can invoke it with any AWS SDK. For instance, you can use the boto3 `invoke_agent_runtime` method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ba323-9e2a-406a-abc3-a93a504701bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps({\"prompt\": \"Analyze APPL Stock\"})\n",
    ")\n",
    "\n",
    "# Use the parsing function we created earlier\n",
    "stock_analysis = parse_bedrock_agentcore_stock_response(boto3_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86824-c775-4ad4-aaee-f18e8cf390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    ")\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1b969-f832-421c-ad21-91f07be0b667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
